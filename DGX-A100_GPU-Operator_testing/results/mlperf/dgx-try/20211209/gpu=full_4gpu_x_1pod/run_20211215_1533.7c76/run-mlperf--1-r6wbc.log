8<--8<--8<--8<--
GPU 0: NVIDIA A100-SXM4-40GB (UUID: GPU-4dd97325-7fe6-abf1-d6a9-ba746fe0fdab)
GPU 1: NVIDIA A100-SXM4-40GB (UUID: GPU-9e13f17f-a213-eb38-9a9c-0b2a540e4908)
GPU 2: NVIDIA A100-SXM4-40GB (UUID: GPU-1ae21a3c-f40b-77a7-002f-4b0b52b05f5b)
GPU 3: NVIDIA A100-SXM4-40GB (UUID: GPU-eeb0f073-2f03-6035-72a3-7b1ac76c5a72)
8<--8<--8<--8<--
++ nvidia-smi -L
++ grep 'UUID: MIG-'
++ wc -l
++ true
+ NB_GPUS=0
+ [[ 0 == 0 ]]
++ nvidia-smi -L
++ grep 'UUID: GPU'
++ cut '-d ' -f6
++ cut '-d)' -f1
+ ALL_GPUS='GPU-4dd97325-7fe6-abf1-d6a9-ba746fe0fdab
GPU-9e13f17f-a213-eb38-9a9c-0b2a540e4908
GPU-1ae21a3c-f40b-77a7-002f-4b0b52b05f5b
GPU-eeb0f073-2f03-6035-72a3-7b1ac76c5a72'
++ nvidia-smi -L
++ grep 'UUID: GPU'
++ wc -l
+ NB_GPUS=4
+ MIG_MODE=0
+ [[ full != \f\u\l\l ]]
+ echo 'No MIG GPU available, using the full GPUs (GPU-4dd97325-7fe6-abf1-d6a9-ba746fe0fdab
GPU-9e13f17f-a213-eb38-9a9c-0b2a540e4908
GPU-1ae21a3c-f40b-77a7-002f-4b0b52b05f5b
GPU-eeb0f073-2f03-6035-72a3-7b1ac76c5a72).'
No MIG GPU available, using the full GPUs (GPU-4dd97325-7fe6-abf1-d6a9-ba746fe0fdab
GPU-9e13f17f-a213-eb38-9a9c-0b2a540e4908
GPU-1ae21a3c-f40b-77a7-002f-4b0b52b05f5b
GPU-eeb0f073-2f03-6035-72a3-7b1ac76c5a72).
+ [[ 4 == 0 ]]
+ [[ 4 != 4 ]]
++ date +%s
+ start=1639578827
++ date '+%Y-%m-%d %r'
+ start_fmt='2021-12-15 02:33:47 PM'
STARTING TIMING RUN AT 2021-12-15 02:33:47 PM GPU: 4 x full x 1 Pods
+ echo 'STARTING TIMING RUN AT 2021-12-15 02:33:47 PM GPU: 4 x full x 1 Pods'
+ set -x
+ export NCCL_DEBUG=INFO
+ NCCL_DEBUG=INFO
running benchmark
+ echo 'running benchmark'
+ export DATASET_DIR=/data/coco2017
+ DATASET_DIR=/data/coco2017
+ export TORCH_HOME=/data/coco2017/torchvision
+ TORCH_HOME=/data/coco2017/torchvision
+ '[' '!' -f /data/coco2017/annotations/bbox_only_instances_val2017.json ']'
+ '[' '!' -f /data/coco2017/annotations/bbox_only_instances_train2017.json ']'
Setting up the Mask RCNN benchmark...
+ [[ maskrcnn == \m\a\s\k\r\c\n\n ]]
+ echo 'Setting up the Mask RCNN benchmark...'
+ NEXP=1
+ source config_DGXA100.sh
++ : False
++ : True
++ : True
++ : 10
++ : True
++ : True
++ : True
++ : 1
++ : True
++ : 40000
++ export BATCHSIZE=12
++ BATCHSIZE=12
++ export EXTRA_PARAMS=
++ EXTRA_PARAMS=
++ export 'EXTRA_CONFIG=SOLVER.BASE_LR 0.12 SOLVER.WARMUP_FACTOR 0.000192 SOLVER.WARMUP_ITERS 625 SOLVER.WARMUP_METHOD mlperf_linear SOLVER.STEPS (12000,16000) SOLVER.IMS_PER_BATCH 96 TEST.IMS_PER_BATCH 96 MODEL.RPN.FPN_POST_NMS_TOP_N_TRAIN 12000 MODEL.RPN.FPN_POST_NMS_TOP_N_PER_IMAGE False NHWC True MODEL.RESNETS.FIRST_TRANS_FUNC FastBottleneckWithFixedBatchNorm MODEL.RESNETS.TRANS_FUNC FastBottleneckWithFixedBatchNorm'
++ EXTRA_CONFIG='SOLVER.BASE_LR 0.12 SOLVER.WARMUP_FACTOR 0.000192 SOLVER.WARMUP_ITERS 625 SOLVER.WARMUP_METHOD mlperf_linear SOLVER.STEPS (12000,16000) SOLVER.IMS_PER_BATCH 96 TEST.IMS_PER_BATCH 96 MODEL.RPN.FPN_POST_NMS_TOP_N_TRAIN 12000 MODEL.RPN.FPN_POST_NMS_TOP_N_PER_IMAGE False NHWC True MODEL.RESNETS.FIRST_TRANS_FUNC FastBottleneckWithFixedBatchNorm MODEL.RESNETS.TRANS_FUNC FastBottleneckWithFixedBatchNorm'
++ export 'EXTRA_CONFIG=SOLVER.BASE_LR 0.12 SOLVER.WARMUP_FACTOR 0.000192 SOLVER.WARMUP_ITERS 625 SOLVER.WARMUP_METHOD mlperf_linear SOLVER.STEPS (12000,16000) SOLVER.IMS_PER_BATCH 96 TEST.IMS_PER_BATCH 96 MODEL.RPN.FPN_POST_NMS_TOP_N_TRAIN 12000 MODEL.RPN.FPN_POST_NMS_TOP_N_PER_IMAGE False NHWC True MODEL.RESNETS.FIRST_TRANS_FUNC FastBottleneckWithFixedBatchNorm MODEL.RESNETS.TRANS_FUNC FastBottleneckWithFixedBatchNorm SOLVER.MAX_ITER 40000 DATALOADER.DALI False DATALOADER.DALI_ON_GPU False DATALOADER.CACHE_EVAL_IMAGES True EVAL_SEGM_NUMPROCS 10 USE_CUDA_GRAPH True EVAL_MASK_VIRTUAL_PASTE True MODEL.BACKBONE.INCLUDE_RPN_HEAD True DATALOADER.NUM_WORKERS 1 PRECOMPUTE_RPN_CONSTANT_TENSORS True DATALOADER.HYBRID True'
++ EXTRA_CONFIG='SOLVER.BASE_LR 0.12 SOLVER.WARMUP_FACTOR 0.000192 SOLVER.WARMUP_ITERS 625 SOLVER.WARMUP_METHOD mlperf_linear SOLVER.STEPS (12000,16000) SOLVER.IMS_PER_BATCH 96 TEST.IMS_PER_BATCH 96 MODEL.RPN.FPN_POST_NMS_TOP_N_TRAIN 12000 MODEL.RPN.FPN_POST_NMS_TOP_N_PER_IMAGE False NHWC True MODEL.RESNETS.FIRST_TRANS_FUNC FastBottleneckWithFixedBatchNorm MODEL.RESNETS.TRANS_FUNC FastBottleneckWithFixedBatchNorm SOLVER.MAX_ITER 40000 DATALOADER.DALI False DATALOADER.DALI_ON_GPU False DATALOADER.CACHE_EVAL_IMAGES True EVAL_SEGM_NUMPROCS 10 USE_CUDA_GRAPH True EVAL_MASK_VIRTUAL_PASTE True MODEL.BACKBONE.INCLUDE_RPN_HEAD True DATALOADER.NUM_WORKERS 1 PRECOMPUTE_RPN_CONSTANT_TENSORS True DATALOADER.HYBRID True'
++ export DGXNNODES=1
++ DGXNNODES=1
+++ sed 's/^config_//'
+++ sed 's/\.sh$//'
++++ readlink -f config_DGXA100.sh
+++ basename /workspace/object_detection/config_DGXA100.sh
++ export DGXSYSTEM=DGXA100
++ DGXSYSTEM=DGXA100
++ WALLTIME_MINUTES=100
++ export WALLTIME=100
++ WALLTIME=100
++ export DGXNGPU=8
++ DGXNGPU=8
++ export DGXSOCKETCORES=64
++ DGXSOCKETCORES=64
++ export DGXNSOCKET=2
++ DGXNSOCKET=2
++ export DGXHT=2
++ DGXHT=2
+ DGXNSOCKET=1
+ DGXSOCKETCORES=64
+ [[ 0 == \1 ]]
+ DGXNGPU=4
+ echo 'Running in multi-gpu mode.'
Running in multi-gpu mode.
+ declare -a CMD
+ CMD=('python' '-u' '-m' 'bind_launch' "--nsockets_per_node=${DGXNSOCKET}" "--ncores_per_socket=${DGXSOCKETCORES}" "--nproc_per_node=${DGXNGPU}")
+ declare -a ARGS
Patching 'bind_launch.py' to err-exit on failure ...
+ echo 'Patching '\''bind_launch.py'\'' to err-exit on failure ...'
+ sed 's/process.wait()$/if process.wait(): sys.exit(1)/' -i bind_launch.py
+ [[ maskrcnn == \s\s\d ]]
+ [[ maskrcnn == \m\a\s\k\r\c\n\n ]]
+ echo 'Setting up the Mask RCNN benchmark...'
Setting up the Mask RCNN benchmark...
+ sed 's/torch.set_num_threads(1)$/import time, sys; time.sleep(int(sys.argv[1].split("=")[-1]));torch.set_num_threads(1);/' -i tools/train_mlperf.py
+ sed 's/fwd_graph.capture_/pass # cannot call fwd_graph.capture_/' -i function.py
+ sed 's/bwd_graph.capture_/pass # cannot call bwd_graph.capture_/' -i function.py
+ MODEL=/data/coco2017/models/R-50.pkl
+ [[ -f /data/coco2017/models/R-50.pkl ]]
++ cat /data/coco2017/models/R-50.pkl
++ md5sum
+ sum='6652b4a9c782d82bb3d42118be74d79b  -'
+ [[ 6652b4a9c782d82bb3d42118be74d79b  - != \6\6\5\2\b\4\a\9\c\7\8\2\d\8\2\b\b\3\d\4\2\1\1\8\b\e\7\4\d\7\9\b\ \ \- ]]
+ [[ ! -f /data/coco2017/models/R-50.pkl ]]
+ COCO_PKL=/data/coco2017/instances_train2017.json.pickled
+ [[ ! -f /data/coco2017/instances_train2017.json.pickled ]]
+ ln -s /data/coco2017/ /pkl_coco
+ ARGS=(tools/train_mlperf.py ${EXTRA_PARAMS} --config-file 'configs/e2e_mask_rcnn_R_50_FPN_1x.yaml' DTYPE 'float16' PATHS_CATALOG 'maskrcnn_benchmark/config/paths_catalog_dbcluster.py' MODEL.WEIGHT "$MODEL" DISABLE_REDUCED_LOGGING True ${EXTRA_CONFIG})
+ [[ run == \d\r\y ]]
+ trap 'date; echo failed; exit 1' ERR
+ [[ n != \y ]]
+ SYNC_DIR=/data/coco2017/sync
+ mkdir -p /data/coco2017/sync
+ for sync_f in "$SYNC_DIR/"*
+ [[ /data/coco2017/sync/2021-12-15_15-31-05 != \/\d\a\t\a\/\c\o\c\o\2\0\1\7\/\s\y\n\c\/\2\0\2\1\-\1\2\-\1\5\_\1\5\-\3\3\-\2\7 ]]
+ rm -f /data/coco2017/sync/2021-12-15_15-31-05
+ set +x
Wed Dec 15 14:33:47 UTC 2021 Waiting for all the 1 Pods to start ...
Adding run-mlperf--1-r6wbc to the sync file ...
Wed Dec 15 14:33:47 UTC 2021 All the 1 Pods are running, launch the GPU workload.
+ nvidia-smi -L
GPU 0: NVIDIA A100-SXM4-40GB (UUID: GPU-4dd97325-7fe6-abf1-d6a9-ba746fe0fdab)
GPU 1: NVIDIA A100-SXM4-40GB (UUID: GPU-9e13f17f-a213-eb38-9a9c-0b2a540e4908)
GPU 2: NVIDIA A100-SXM4-40GB (UUID: GPU-1ae21a3c-f40b-77a7-002f-4b0b52b05f5b)
GPU 3: NVIDIA A100-SXM4-40GB (UUID: GPU-eeb0f073-2f03-6035-72a3-7b1ac76c5a72)
+ [[ 0 == 1 ]]
+ dest=/tmp/benchmark_all.log
+ [[ 0 == 1 ]]
Running on all the 4 GPUs 
+ echo 'Running on all the 4 GPUs '
+ python -u -m bind_launch --nsockets_per_node=1 --ncores_per_socket=64 --nproc_per_node=4 tools/train_mlperf.py --config-file configs/e2e_mask_rcnn_R_50_FPN_1x.yaml DTYPE float16 PATHS_CATALOG maskrcnn_benchmark/config/paths_catalog_dbcluster.py MODEL.WEIGHT /data/coco2017/models/R-50.pkl DISABLE_REDUCED_LOGGING True SOLVER.BASE_LR 0.12 SOLVER.WARMUP_FACTOR 0.000192 SOLVER.WARMUP_ITERS 625 SOLVER.WARMUP_METHOD mlperf_linear SOLVER.STEPS '(12000,16000)' SOLVER.IMS_PER_BATCH 96 TEST.IMS_PER_BATCH 96 MODEL.RPN.FPN_POST_NMS_TOP_N_TRAIN 12000 MODEL.RPN.FPN_POST_NMS_TOP_N_PER_IMAGE False NHWC True MODEL.RESNETS.FIRST_TRANS_FUNC FastBottleneckWithFixedBatchNorm MODEL.RESNETS.TRANS_FUNC FastBottleneckWithFixedBatchNorm SOLVER.MAX_ITER 40000 DATALOADER.DALI False DATALOADER.DALI_ON_GPU False DATALOADER.CACHE_EVAL_IMAGES True EVAL_SEGM_NUMPROCS 10 USE_CUDA_GRAPH True EVAL_MASK_VIRTUAL_PASTE True MODEL.BACKBONE.INCLUDE_RPN_HEAD True DATALOADER.NUM_WORKERS 1 PRECOMPUTE_RPN_CONSTANT_TENSORS True DATALOADER.HYBRID True
+ tee -a /tmp/benchmark_all.log
:::MLLOG {"namespace": "", "time_ms": 1639578829815, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "tools/train_mlperf.py", "lineno": 658}}
:::MLLOG {"namespace": "", "time_ms": 1639578830782, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "tools/train_mlperf.py", "lineno": 658}}
:::MLLOG {"namespace": "", "time_ms": 1639578831811, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "tools/train_mlperf.py", "lineno": 658}}
:::MLLOG {"namespace": "", "time_ms": 1639578832794, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "tools/train_mlperf.py", "lineno": 658}}
run-mlperf--1-r6wbc:62:62 [0] NCCL INFO Bootstrap : Using eth0:10.128.1.139<0>
run-mlperf--1-r6wbc:62:62 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
run-mlperf--1-r6wbc:62:62 [0] NCCL INFO P2P plugin IBext
run-mlperf--1-r6wbc:62:62 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/RoCE [1]mlx5_7:1/RoCE ; OOB eth0:10.128.1.139<0>
run-mlperf--1-r6wbc:62:62 [0] NCCL INFO Using network IBext
NCCL version 2.11.4+cuda11.4
run-mlperf--1-r6wbc:64:64 [2] NCCL INFO Bootstrap : Using eth0:10.128.1.139<0>
run-mlperf--1-r6wbc:64:64 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
run-mlperf--1-r6wbc:64:64 [2] NCCL INFO P2P plugin IBext
run-mlperf--1-r6wbc:63:63 [1] NCCL INFO Bootstrap : Using eth0:10.128.1.139<0>
run-mlperf--1-r6wbc:65:65 [3] NCCL INFO Bootstrap : Using eth0:10.128.1.139<0>
run-mlperf--1-r6wbc:63:63 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
run-mlperf--1-r6wbc:63:63 [1] NCCL INFO P2P plugin IBext
run-mlperf--1-r6wbc:65:65 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
run-mlperf--1-r6wbc:65:65 [3] NCCL INFO P2P plugin IBext
run-mlperf--1-r6wbc:64:64 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/RoCE [1]mlx5_7:1/RoCE ; OOB eth0:10.128.1.139<0>
run-mlperf--1-r6wbc:64:64 [2] NCCL INFO Using network IBext
run-mlperf--1-r6wbc:65:65 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/RoCE [1]mlx5_7:1/RoCE ; OOB eth0:10.128.1.139<0>
run-mlperf--1-r6wbc:63:63 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/RoCE [1]mlx5_7:1/RoCE ; OOB eth0:10.128.1.139<0>
run-mlperf--1-r6wbc:65:65 [3] NCCL INFO Using network IBext
run-mlperf--1-r6wbc:63:63 [1] NCCL INFO Using network IBext
run-mlperf--1-r6wbc:62:1110 [0] NCCL INFO Channel 00/24 :    0   1   2   3
run-mlperf--1-r6wbc:62:1110 [0] NCCL INFO Channel 01/24 :    0   1   2   3
run-mlperf--1-r6wbc:62:1110 [0] NCCL INFO Channel 02/24 :    0   1   2   3
run-mlperf--1-r6wbc:62:1110 [0] NCCL INFO Channel 03/24 :    0   1   2   3
run-mlperf--1-r6wbc:64:1115 [2] NCCL INFO Trees [0] 3/-1/-1->2->1 [1] 3/-1/-1->2->1 [2] 3/-1/-1->2->1 [3] 3/-1/-1->2->1 [4] 3/-1/-1->2->1 [5] 3/-1/-1->2->1 [6] 3/-1/-1->2->1 [7] 3/-1/-1->2->1 [8] 3/-1/-1->2->1 [9] 3/-1/-1->2->1 [10] 3/-1/-1->2->1 [11] 3/-1/-1->2->1 [12] 3/-1/-1->2->1 [13] 3/-1/-1->2->1 [14] 3/-1/-1->2->1 [15] 3/-1/-1->2->1 [16] 3/-1/-1->2->1 [17] 3/-1/-1->2->1 [18] 3/-1/-1->2->1 [19] 3/-1/-1->2->1 [20] 3/-1/-1->2->1 [21] 3/-1/-1->2->1 [22] 3/-1/-1->2->1 [23] 3/-1/-1->2->1
run-mlperf--1-r6wbc:62:1110 [0] NCCL INFO Channel 04/24 :    0   1   2   3
run-mlperf--1-r6wbc:62:1110 [0] NCCL INFO Channel 05/24 :    0   1   2   3
run-mlperf--1-r6wbc:63:1119 [1] NCCL INFO Trees [0] 2/-1/-1->1->0 [1] 2/-1/-1->1->0 [2] 2/-1/-1->1->0 [3] 2/-1/-1->1->0 [4] 2/-1/-1->1->0 [5] 2/-1/-1->1->0 [6] 2/-1/-1->1->0 [7] 2/-1/-1->1->0 [8] 2/-1/-1->1->0 [9] 2/-1/-1->1->0 [10] 2/-1/-1->1->0 [11] 2/-1/-1->1->0 [12] 2/-1/-1->1->0 [13] 2/-1/-1->1->0 [14] 2/-1/-1->1->0 [15] 2/-1/-1->1->0 [16] 2/-1/-1->1->0 [17] 2/-1/-1->1->0 [18] 2/-1/-1->1->0 [19] 2/-1/-1->1->0 [20] 2/-1/-1->1->0 [21] 2/-1/-1->1->0 [22] 2/-1/-1->1->0 [23] 2/-1/-1->1->0
run-mlperf--1-r6wbc:62:1110 [0] NCCL INFO Channel 06/24 :    0   1   2   3
run-mlperf--1-r6wbc:62:1110 [0] NCCL INFO Channel 07/24 :    0   1   2   3
run-mlperf--1-r6wbc:65:1118 [3] NCCL INFO Trees [0] -1/-1/-1->3->2 [1] -1/-1/-1->3->2 [2] -1/-1/-1->3->2 [3] -1/-1/-1->3->2 [4] -1/-1/-1->3->2 [5] -1/-1/-1->3->2 [6] -1/-1/-1->3->2 [7] -1/-1/-1->3->2 [8] -1/-1/-1->3->2 [9] -1/-1/-1->3->2 [10] -1/-1/-1->3->2 [11] -1/-1/-1->3->2 [12] -1/-1/-1->3->2 [13] -1/-1/-1->3->2 [14] -1/-1/-1->3->2 [15] -1/-1/-1->3->2 [16] -1/-1/-1->3->2 [17] -1/-1/-1->3->2 [18] -1/-1/-1->3->2 [19] -1/-1/-1->3->2 [20] -1/-1/-1->3->2 [21] -1/-1/-1->3->2 [22] -1/-1/-1->3->2 [23] -1/-1/-1->3->2
run-mlperf--1-r6wbc:62:1110 [0] NCCL INFO Channel 08/24 :    0   1   2   3
run-mlperf--1-r6wbc:62:1110 [0] NCCL INFO Channel 09/24 :    0   1   2   3
run-mlperf--1-r6wbc:62:1110 [0] NCCL INFO Channel 10/24 :    0   1   2   3
run-mlperf--1-r6wbc:62:1110 [0] NCCL INFO Channel 11/24 :    0   1   2   3
run-mlperf--1-r6wbc:62:1110 [0] NCCL INFO Channel 12/24 :    0   1   2   3
run-mlperf--1-r6wbc:62:1110 [0] NCCL INFO Channel 13/24 :    0   1   2   3
run-mlperf--1-r6wbc:62:1110 [0] NCCL INFO Channel 14/24 :    0   1   2   3
run-mlperf--1-r6wbc:62:1110 [0] NCCL INFO Channel 15/24 :    0   1   2   3
run-mlperf--1-r6wbc:62:1110 [0] NCCL INFO Channel 16/24 :    0   1   2   3
run-mlperf--1-r6wbc:62:1110 [0] NCCL INFO Channel 17/24 :    0   1   2   3
run-mlperf--1-r6wbc:62:1110 [0] NCCL INFO Channel 18/24 :    0   1   2   3
run-mlperf--1-r6wbc:62:1110 [0] NCCL INFO Channel 19/24 :    0   1   2   3
run-mlperf--1-r6wbc:62:1110 [0] NCCL INFO Channel 20/24 :    0   1   2   3
run-mlperf--1-r6wbc:62:1110 [0] NCCL INFO Channel 21/24 :    0   1   2   3
run-mlperf--1-r6wbc:62:1110 [0] NCCL INFO Channel 22/24 :    0   1   2   3
run-mlperf--1-r6wbc:62:1110 [0] NCCL INFO Channel 23/24 :    0   1   2   3
run-mlperf--1-r6wbc:62:1110 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] 1/-1/-1->0->-1 [2] 1/-1/-1->0->-1 [3] 1/-1/-1->0->-1 [4] 1/-1/-1->0->-1 [5] 1/-1/-1->0->-1 [6] 1/-1/-1->0->-1 [7] 1/-1/-1->0->-1 [8] 1/-1/-1->0->-1 [9] 1/-1/-1->0->-1 [10] 1/-1/-1->0->-1 [11] 1/-1/-1->0->-1 [12] 1/-1/-1->0->-1 [13] 1/-1/-1->0->-1 [14] 1/-1/-1->0->-1 [15] 1/-1/-1->0->-1 [16] 1/-1/-1->0->-1 [17] 1/-1/-1->0->-1 [18] 1/-1/-1->0->-1 [19] 1/-1/-1->0->-1 [20] 1/-1/-1->0->-1 [21] 1/-1/-1->0->-1 [22] 1/-1/-1->0->-1 [23] 1/-1/-1->0->-1
run-mlperf--1-r6wbc:64:1115 [2] NCCL INFO Channel 00 : 2[47000] -> 3[4e000] via P2P/IPC/read
run-mlperf--1-r6wbc:62:1110 [0] NCCL INFO Channel 00 : 0[7000] -> 1[f000] via P2P/IPC/read
run-mlperf--1-r6wbc:65:1118 [3] NCCL INFO Channel 00 : 3[4e000] -> 0[7000] via P2P/IPC/read
run-mlperf--1-r6wbc:63:1119 [1] NCCL INFO Channel 00 : 1[f000] -> 2[47000] via P2P/IPC/read
run-mlperf--1-r6wbc:64:1115 [2] NCCL INFO Channel 01 : 2[47000] -> 3[4e000] via P2P/IPC/read
run-mlperf--1-r6wbc:62:1110 [0] NCCL INFO Channel 01 : 0[7000] -> 1[f000] via P2P/IPC/read
run-mlperf--1-r6wbc:65:1118 [3] NCCL INFO Channel 01 : 3[4e000] -> 0[7000] via P2P/IPC/read
run-mlperf--1-r6wbc:63:1119 [1] NCCL INFO Channel 01 : 1[f000] -> 2[47000] via P2P/IPC/read
run-mlperf--1-r6wbc:64:1115 [2] NCCL INFO Channel 02 : 2[47000] -> 3[4e000] via P2P/IPC/read
run-mlperf--1-r6wbc:62:1110 [0] NCCL INFO Channel 02 : 0[7000] -> 1[f000] via P2P/IPC/read
run-mlperf--1-r6wbc:65:1118 [3] NCCL INFO Channel 02 : 3[4e000] -> 0[7000] via P2P/IPC/read
run-mlperf--1-r6wbc:63:1119 [1] NCCL INFO Channel 02 : 1[f000] -> 2[47000] via P2P/IPC/read
run-mlperf--1-r6wbc:64:1115 [2] NCCL INFO Channel 03 : 2[47000] -> 3[4e000] via P2P/IPC/read
run-mlperf--1-r6wbc:62:1110 [0] NCCL INFO Channel 03 : 0[7000] -> 1[f000] via P2P/IPC/read
run-mlperf--1-r6wbc:65:1118 [3] NCCL INFO Channel 03 : 3[4e000] -> 0[7000] via P2P/IPC/read
run-mlperf--1-r6wbc:63:1119 [1] NCCL INFO Channel 03 : 1[f000] -> 2[47000] via P2P/IPC/read
run-mlperf--1-r6wbc:64:1115 [2] NCCL INFO Channel 04 : 2[47000] -> 3[4e000] via P2P/IPC/read
run-mlperf--1-r6wbc:62:1110 [0] NCCL INFO Channel 04 : 0[7000] -> 1[f000] via P2P/IPC/read
run-mlperf--1-r6wbc:65:1118 [3] NCCL INFO Channel 04 : 3[4e000] -> 0[7000] via P2P/IPC/read
run-mlperf--1-r6wbc:63:1119 [1] NCCL INFO Channel 04 : 1[f000] -> 2[47000] via P2P/IPC/read
run-mlperf--1-r6wbc:64:1115 [2] NCCL INFO Channel 05 : 2[47000] -> 3[4e000] via P2P/IPC/read
run-mlperf--1-r6wbc:62:1110 [0] NCCL INFO Channel 05 : 0[7000] -> 1[f000] via P2P/IPC/read
run-mlperf--1-r6wbc:65:1118 [3] NCCL INFO Channel 05 : 3[4e000] -> 0[7000] via P2P/IPC/read
run-mlperf--1-r6wbc:63:1119 [1] NCCL INFO Channel 05 : 1[f000] -> 2[47000] via P2P/IPC/read
run-mlperf--1-r6wbc:64:1115 [2] NCCL INFO Channel 06 : 2[47000] -> 3[4e000] via P2P/IPC/read
run-mlperf--1-r6wbc:62:1110 [0] NCCL INFO Channel 06 : 0[7000] -> 1[f000] via P2P/IPC/read
run-mlperf--1-r6wbc:65:1118 [3] NCCL INFO Channel 06 : 3[4e000] -> 0[7000] via P2P/IPC/read
run-mlperf--1-r6wbc:63:1119 [1] NCCL INFO Channel 06 : 1[f000] -> 2[47000] via P2P/IPC/read
run-mlperf--1-r6wbc:64:1115 [2] NCCL INFO Channel 07 : 2[47000] -> 3[4e000] via P2P/IPC/read
run-mlperf--1-r6wbc:62:1110 [0] NCCL INFO Channel 07 : 0[7000] -> 1[f000] via P2P/IPC/read
run-mlperf--1-r6wbc:65:1118 [3] NCCL INFO Channel 07 : 3[4e000] -> 0[7000] via P2P/IPC/read
run-mlperf--1-r6wbc:63:1119 [1] NCCL INFO Channel 07 : 1[f000] -> 2[47000] via P2P/IPC/read
run-mlperf--1-r6wbc:64:1115 [2] NCCL INFO Channel 08 : 2[47000] -> 3[4e000] via P2P/IPC/read
run-mlperf--1-r6wbc:62:1110 [0] NCCL INFO Channel 08 : 0[7000] -> 1[f000] via P2P/IPC/read
run-mlperf--1-r6wbc:65:1118 [3] NCCL INFO Channel 08 : 3[4e000] -> 0[7000] via P2P/IPC/read
run-mlperf--1-r6wbc:63:1119 [1] NCCL INFO Channel 08 : 1[f000] -> 2[47000] via P2P/IPC/read
run-mlperf--1-r6wbc:64:1115 [2] NCCL INFO Channel 09 : 2[47000] -> 3[4e000] via P2P/IPC/read
run-mlperf--1-r6wbc:62:1110 [0] NCCL INFO Channel 09 : 0[7000] -> 1[f000] via P2P/IPC/read
run-mlperf--1-r6wbc:65:1118 [3] NCCL INFO Channel 09 : 3[4e000] -> 0[7000] via P2P/IPC/read
run-mlperf--1-r6wbc:63:1119 [1] NCCL INFO Channel 09 : 1[f000] -> 2[47000] via P2P/IPC/read
run-mlperf--1-r6wbc:64:1115 [2] NCCL INFO Channel 10 : 2[47000] -> 3[4e000] via P2P/IPC/read
run-mlperf--1-r6wbc:62:1110 [0] NCCL INFO Channel 10 : 0[7000] -> 1[f000] via P2P/IPC/read
run-mlperf--1-r6wbc:65:1118 [3] NCCL INFO Channel 10 : 3[4e000] -> 0[7000] via P2P/IPC/read
run-mlperf--1-r6wbc:63:1119 [1] NCCL INFO Channel 10 : 1[f000] -> 2[47000] via P2P/IPC/read
run-mlperf--1-r6wbc:64:1115 [2] NCCL INFO Channel 11 : 2[47000] -> 3[4e000] via P2P/IPC/read
run-mlperf--1-r6wbc:62:1110 [0] NCCL INFO Channel 11 : 0[7000] -> 1[f000] via P2P/IPC/read
run-mlperf--1-r6wbc:65:1118 [3] NCCL INFO Channel 11 : 3[4e000] -> 0[7000] via P2P/IPC/read
run-mlperf--1-r6wbc:63:1119 [1] NCCL INFO Channel 11 : 1[f000] -> 2[47000] via P2P/IPC/read
run-mlperf--1-r6wbc:64:1115 [2] NCCL INFO Channel 12 : 2[47000] -> 3[4e000] via P2P/IPC/read
run-mlperf--1-r6wbc:62:1110 [0] NCCL INFO Channel 12 : 0[7000] -> 1[f000] via P2P/IPC/read
run-mlperf--1-r6wbc:65:1118 [3] NCCL INFO Channel 12 : 3[4e000] -> 0[7000] via P2P/IPC/read
run-mlperf--1-r6wbc:63:1119 [1] NCCL INFO Channel 12 : 1[f000] -> 2[47000] via P2P/IPC/read
run-mlperf--1-r6wbc:64:1115 [2] NCCL INFO Channel 13 : 2[47000] -> 3[4e000] via P2P/IPC/read
run-mlperf--1-r6wbc:62:1110 [0] NCCL INFO Channel 13 : 0[7000] -> 1[f000] via P2P/IPC/read
run-mlperf--1-r6wbc:65:1118 [3] NCCL INFO Channel 13 : 3[4e000] -> 0[7000] via P2P/IPC/read
run-mlperf--1-r6wbc:63:1119 [1] NCCL INFO Channel 13 : 1[f000] -> 2[47000] via P2P/IPC/read
run-mlperf--1-r6wbc:64:1115 [2] NCCL INFO Channel 14 : 2[47000] -> 3[4e000] via P2P/IPC/read
run-mlperf--1-r6wbc:62:1110 [0] NCCL INFO Channel 14 : 0[7000] -> 1[f000] via P2P/IPC/read
run-mlperf--1-r6wbc:65:1118 [3] NCCL INFO Channel 14 : 3[4e000] -> 0[7000] via P2P/IPC/read
run-mlperf--1-r6wbc:63:1119 [1] NCCL INFO Channel 14 : 1[f000] -> 2[47000] via P2P/IPC/read
run-mlperf--1-r6wbc:64:1115 [2] NCCL INFO Channel 15 : 2[47000] -> 3[4e000] via P2P/IPC/read
run-mlperf--1-r6wbc:62:1110 [0] NCCL INFO Channel 15 : 0[7000] -> 1[f000] via P2P/IPC/read
run-mlperf--1-r6wbc:65:1118 [3] NCCL INFO Channel 15 : 3[4e000] -> 0[7000] via P2P/IPC/read
run-mlperf--1-r6wbc:63:1119 [1] NCCL INFO Channel 15 : 1[f000] -> 2[47000] via P2P/IPC/read
run-mlperf--1-r6wbc:64:1115 [2] NCCL INFO Channel 16 : 2[47000] -> 3[4e000] via P2P/IPC/read
run-mlperf--1-r6wbc:62:1110 [0] NCCL INFO Channel 16 : 0[7000] -> 1[f000] via P2P/IPC/read
run-mlperf--1-r6wbc:65:1118 [3] NCCL INFO Channel 16 : 3[4e000] -> 0[7000] via P2P/IPC/read
run-mlperf--1-r6wbc:63:1119 [1] NCCL INFO Channel 16 : 1[f000] -> 2[47000] via P2P/IPC/read
run-mlperf--1-r6wbc:64:1115 [2] NCCL INFO Channel 17 : 2[47000] -> 3[4e000] via P2P/IPC/read
run-mlperf--1-r6wbc:62:1110 [0] NCCL INFO Channel 17 : 0[7000] -> 1[f000] via P2P/IPC/read
run-mlperf--1-r6wbc:65:1118 [3] NCCL INFO Channel 17 : 3[4e000] -> 0[7000] via P2P/IPC/read
run-mlperf--1-r6wbc:63:1119 [1] NCCL INFO Channel 17 : 1[f000] -> 2[47000] via P2P/IPC/read
run-mlperf--1-r6wbc:64:1115 [2] NCCL INFO Channel 18 : 2[47000] -> 3[4e000] via P2P/IPC/read
run-mlperf--1-r6wbc:62:1110 [0] NCCL INFO Channel 18 : 0[7000] -> 1[f000] via P2P/IPC/read
run-mlperf--1-r6wbc:65:1118 [3] NCCL INFO Channel 18 : 3[4e000] -> 0[7000] via P2P/IPC/read
run-mlperf--1-r6wbc:63:1119 [1] NCCL INFO Channel 18 : 1[f000] -> 2[47000] via P2P/IPC/read
run-mlperf--1-r6wbc:64:1115 [2] NCCL INFO Channel 19 : 2[47000] -> 3[4e000] via P2P/IPC/read
run-mlperf--1-r6wbc:62:1110 [0] NCCL INFO Channel 19 : 0[7000] -> 1[f000] via P2P/IPC/read
run-mlperf--1-r6wbc:65:1118 [3] NCCL INFO Channel 19 : 3[4e000] -> 0[7000] via P2P/IPC/read
run-mlperf--1-r6wbc:63:1119 [1] NCCL INFO Channel 19 : 1[f000] -> 2[47000] via P2P/IPC/read
run-mlperf--1-r6wbc:64:1115 [2] NCCL INFO Channel 20 : 2[47000] -> 3[4e000] via P2P/IPC/read
run-mlperf--1-r6wbc:62:1110 [0] NCCL INFO Channel 20 : 0[7000] -> 1[f000] via P2P/IPC/read
run-mlperf--1-r6wbc:65:1118 [3] NCCL INFO Channel 20 : 3[4e000] -> 0[7000] via P2P/IPC/read
run-mlperf--1-r6wbc:63:1119 [1] NCCL INFO Channel 20 : 1[f000] -> 2[47000] via P2P/IPC/read
run-mlperf--1-r6wbc:64:1115 [2] NCCL INFO Channel 21 : 2[47000] -> 3[4e000] via P2P/IPC/read
run-mlperf--1-r6wbc:62:1110 [0] NCCL INFO Channel 21 : 0[7000] -> 1[f000] via P2P/IPC/read
run-mlperf--1-r6wbc:65:1118 [3] NCCL INFO Channel 21 : 3[4e000] -> 0[7000] via P2P/IPC/read
run-mlperf--1-r6wbc:63:1119 [1] NCCL INFO Channel 21 : 1[f000] -> 2[47000] via P2P/IPC/read
run-mlperf--1-r6wbc:64:1115 [2] NCCL INFO Channel 22 : 2[47000] -> 3[4e000] via P2P/IPC/read
run-mlperf--1-r6wbc:62:1110 [0] NCCL INFO Channel 22 : 0[7000] -> 1[f000] via P2P/IPC/read
run-mlperf--1-r6wbc:65:1118 [3] NCCL INFO Channel 22 : 3[4e000] -> 0[7000] via P2P/IPC/read
run-mlperf--1-r6wbc:63:1119 [1] NCCL INFO Channel 22 : 1[f000] -> 2[47000] via P2P/IPC/read
run-mlperf--1-r6wbc:64:1115 [2] NCCL INFO Channel 23 : 2[47000] -> 3[4e000] via P2P/IPC/read
run-mlperf--1-r6wbc:62:1110 [0] NCCL INFO Channel 23 : 0[7000] -> 1[f000] via P2P/IPC/read
run-mlperf--1-r6wbc:65:1118 [3] NCCL INFO Channel 23 : 3[4e000] -> 0[7000] via P2P/IPC/read
run-mlperf--1-r6wbc:63:1119 [1] NCCL INFO Channel 23 : 1[f000] -> 2[47000] via P2P/IPC/read
run-mlperf--1-r6wbc:62:1110 [0] NCCL INFO Connected all rings
run-mlperf--1-r6wbc:65:1118 [3] NCCL INFO Connected all rings
run-mlperf--1-r6wbc:64:1115 [2] NCCL INFO Connected all rings
run-mlperf--1-r6wbc:63:1119 [1] NCCL INFO Connected all rings
run-mlperf--1-r6wbc:65:1118 [3] NCCL INFO Channel 00 : 3[4e000] -> 2[47000] via P2P/IPC/read
run-mlperf--1-r6wbc:65:1118 [3] NCCL INFO Channel 01 : 3[4e000] -> 2[47000] via P2P/IPC/read
run-mlperf--1-r6wbc:65:1118 [3] NCCL INFO Channel 02 : 3[4e000] -> 2[47000] via P2P/IPC/read
run-mlperf--1-r6wbc:65:1118 [3] NCCL INFO Channel 03 : 3[4e000] -> 2[47000] via P2P/IPC/read
run-mlperf--1-r6wbc:65:1118 [3] NCCL INFO Channel 04 : 3[4e000] -> 2[47000] via P2P/IPC/read
run-mlperf--1-r6wbc:65:1118 [3] NCCL INFO Channel 05 : 3[4e000] -> 2[47000] via P2P/IPC/read
run-mlperf--1-r6wbc:65:1118 [3] NCCL INFO Channel 06 : 3[4e000] -> 2[47000] via P2P/IPC/read
run-mlperf--1-r6wbc:65:1118 [3] NCCL INFO Channel 07 : 3[4e000] -> 2[47000] via P2P/IPC/read
run-mlperf--1-r6wbc:65:1118 [3] NCCL INFO Channel 08 : 3[4e000] -> 2[47000] via P2P/IPC/read
run-mlperf--1-r6wbc:65:1118 [3] NCCL INFO Channel 09 : 3[4e000] -> 2[47000] via P2P/IPC/read
run-mlperf--1-r6wbc:65:1118 [3] NCCL INFO Channel 10 : 3[4e000] -> 2[47000] via P2P/IPC/read
run-mlperf--1-r6wbc:65:1118 [3] NCCL INFO Channel 11 : 3[4e000] -> 2[47000] via P2P/IPC/read
run-mlperf--1-r6wbc:65:1118 [3] NCCL INFO Channel 12 : 3[4e000] -> 2[47000] via P2P/IPC/read
run-mlperf--1-r6wbc:65:1118 [3] NCCL INFO Channel 13 : 3[4e000] -> 2[47000] via P2P/IPC/read
run-mlperf--1-r6wbc:65:1118 [3] NCCL INFO Channel 14 : 3[4e000] -> 2[47000] via P2P/IPC/read
run-mlperf--1-r6wbc:65:1118 [3] NCCL INFO Channel 15 : 3[4e000] -> 2[47000] via P2P/IPC/read
run-mlperf--1-r6wbc:65:1118 [3] NCCL INFO Channel 16 : 3[4e000] -> 2[47000] via P2P/IPC/read
run-mlperf--1-r6wbc:65:1118 [3] NCCL INFO Channel 17 : 3[4e000] -> 2[47000] via P2P/IPC/read
run-mlperf--1-r6wbc:65:1118 [3] NCCL INFO Channel 18 : 3[4e000] -> 2[47000] via P2P/IPC/read
run-mlperf--1-r6wbc:65:1118 [3] NCCL INFO Channel 19 : 3[4e000] -> 2[47000] via P2P/IPC/read
run-mlperf--1-r6wbc:65:1118 [3] NCCL INFO Channel 20 : 3[4e000] -> 2[47000] via P2P/IPC/read
run-mlperf--1-r6wbc:65:1118 [3] NCCL INFO Channel 21 : 3[4e000] -> 2[47000] via P2P/IPC/read
run-mlperf--1-r6wbc:65:1118 [3] NCCL INFO Channel 22 : 3[4e000] -> 2[47000] via P2P/IPC/read
run-mlperf--1-r6wbc:65:1118 [3] NCCL INFO Channel 23 : 3[4e000] -> 2[47000] via P2P/IPC/read
run-mlperf--1-r6wbc:64:1115 [2] NCCL INFO Channel 00 : 2[47000] -> 1[f000] via P2P/IPC/read
run-mlperf--1-r6wbc:63:1119 [1] NCCL INFO Channel 00 : 1[f000] -> 0[7000] via P2P/IPC/read
run-mlperf--1-r6wbc:64:1115 [2] NCCL INFO Channel 01 : 2[47000] -> 1[f000] via P2P/IPC/read
run-mlperf--1-r6wbc:63:1119 [1] NCCL INFO Channel 01 : 1[f000] -> 0[7000] via P2P/IPC/read
run-mlperf--1-r6wbc:64:1115 [2] NCCL INFO Channel 02 : 2[47000] -> 1[f000] via P2P/IPC/read
run-mlperf--1-r6wbc:63:1119 [1] NCCL INFO Channel 02 : 1[f000] -> 0[7000] via P2P/IPC/read
run-mlperf--1-r6wbc:64:1115 [2] NCCL INFO Channel 03 : 2[47000] -> 1[f000] via P2P/IPC/read
run-mlperf--1-r6wbc:63:1119 [1] NCCL INFO Channel 03 : 1[f000] -> 0[7000] via P2P/IPC/read
run-mlperf--1-r6wbc:64:1115 [2] NCCL INFO Channel 04 : 2[47000] -> 1[f000] via P2P/IPC/read
run-mlperf--1-r6wbc:63:1119 [1] NCCL INFO Channel 04 : 1[f000] -> 0[7000] via P2P/IPC/read
run-mlperf--1-r6wbc:64:1115 [2] NCCL INFO Channel 05 : 2[47000] -> 1[f000] via P2P/IPC/read
run-mlperf--1-r6wbc:63:1119 [1] NCCL INFO Channel 05 : 1[f000] -> 0[7000] via P2P/IPC/read
run-mlperf--1-r6wbc:64:1115 [2] NCCL INFO Channel 06 : 2[47000] -> 1[f000] via P2P/IPC/read
run-mlperf--1-r6wbc:63:1119 [1] NCCL INFO Channel 06 : 1[f000] -> 0[7000] via P2P/IPC/read
run-mlperf--1-r6wbc:64:1115 [2] NCCL INFO Channel 07 : 2[47000] -> 1[f000] via P2P/IPC/read
run-mlperf--1-r6wbc:63:1119 [1] NCCL INFO Channel 07 : 1[f000] -> 0[7000] via P2P/IPC/read
run-mlperf--1-r6wbc:64:1115 [2] NCCL INFO Channel 08 : 2[47000] -> 1[f000] via P2P/IPC/read
run-mlperf--1-r6wbc:63:1119 [1] NCCL INFO Channel 08 : 1[f000] -> 0[7000] via P2P/IPC/read
run-mlperf--1-r6wbc:64:1115 [2] NCCL INFO Channel 09 : 2[47000] -> 1[f000] via P2P/IPC/read
run-mlperf--1-r6wbc:63:1119 [1] NCCL INFO Channel 09 : 1[f000] -> 0[7000] via P2P/IPC/read
run-mlperf--1-r6wbc:64:1115 [2] NCCL INFO Channel 10 : 2[47000] -> 1[f000] via P2P/IPC/read
run-mlperf--1-r6wbc:63:1119 [1] NCCL INFO Channel 10 : 1[f000] -> 0[7000] via P2P/IPC/read
run-mlperf--1-r6wbc:64:1115 [2] NCCL INFO Channel 11 : 2[47000] -> 1[f000] via P2P/IPC/read
run-mlperf--1-r6wbc:63:1119 [1] NCCL INFO Channel 11 : 1[f000] -> 0[7000] via P2P/IPC/read
run-mlperf--1-r6wbc:64:1115 [2] NCCL INFO Channel 12 : 2[47000] -> 1[f000] via P2P/IPC/read
run-mlperf--1-r6wbc:63:1119 [1] NCCL INFO Channel 12 : 1[f000] -> 0[7000] via P2P/IPC/read
run-mlperf--1-r6wbc:64:1115 [2] NCCL INFO Channel 13 : 2[47000] -> 1[f000] via P2P/IPC/read
run-mlperf--1-r6wbc:63:1119 [1] NCCL INFO Channel 13 : 1[f000] -> 0[7000] via P2P/IPC/read
run-mlperf--1-r6wbc:64:1115 [2] NCCL INFO Channel 14 : 2[47000] -> 1[f000] via P2P/IPC/read
run-mlperf--1-r6wbc:63:1119 [1] NCCL INFO Channel 14 : 1[f000] -> 0[7000] via P2P/IPC/read
run-mlperf--1-r6wbc:64:1115 [2] NCCL INFO Channel 15 : 2[47000] -> 1[f000] via P2P/IPC/read
run-mlperf--1-r6wbc:63:1119 [1] NCCL INFO Channel 15 : 1[f000] -> 0[7000] via P2P/IPC/read
run-mlperf--1-r6wbc:64:1115 [2] NCCL INFO Channel 16 : 2[47000] -> 1[f000] via P2P/IPC/read
run-mlperf--1-r6wbc:63:1119 [1] NCCL INFO Channel 16 : 1[f000] -> 0[7000] via P2P/IPC/read
run-mlperf--1-r6wbc:64:1115 [2] NCCL INFO Channel 17 : 2[47000] -> 1[f000] via P2P/IPC/read
run-mlperf--1-r6wbc:63:1119 [1] NCCL INFO Channel 17 : 1[f000] -> 0[7000] via P2P/IPC/read
run-mlperf--1-r6wbc:64:1115 [2] NCCL INFO Channel 18 : 2[47000] -> 1[f000] via P2P/IPC/read
run-mlperf--1-r6wbc:63:1119 [1] NCCL INFO Channel 18 : 1[f000] -> 0[7000] via P2P/IPC/read
run-mlperf--1-r6wbc:64:1115 [2] NCCL INFO Channel 19 : 2[47000] -> 1[f000] via P2P/IPC/read
run-mlperf--1-r6wbc:63:1119 [1] NCCL INFO Channel 19 : 1[f000] -> 0[7000] via P2P/IPC/read
run-mlperf--1-r6wbc:64:1115 [2] NCCL INFO Channel 20 : 2[47000] -> 1[f000] via P2P/IPC/read
run-mlperf--1-r6wbc:63:1119 [1] NCCL INFO Channel 20 : 1[f000] -> 0[7000] via P2P/IPC/read
run-mlperf--1-r6wbc:64:1115 [2] NCCL INFO Channel 21 : 2[47000] -> 1[f000] via P2P/IPC/read
run-mlperf--1-r6wbc:63:1119 [1] NCCL INFO Channel 21 : 1[f000] -> 0[7000] via P2P/IPC/read
run-mlperf--1-r6wbc:64:1115 [2] NCCL INFO Channel 22 : 2[47000] -> 1[f000] via P2P/IPC/read
run-mlperf--1-r6wbc:63:1119 [1] NCCL INFO Channel 22 : 1[f000] -> 0[7000] via P2P/IPC/read
run-mlperf--1-r6wbc:64:1115 [2] NCCL INFO Channel 23 : 2[47000] -> 1[f000] via P2P/IPC/read
run-mlperf--1-r6wbc:63:1119 [1] NCCL INFO Channel 23 : 1[f000] -> 0[7000] via P2P/IPC/read
run-mlperf--1-r6wbc:65:1118 [3] NCCL INFO Connected all trees
run-mlperf--1-r6wbc:65:1118 [3] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 8/8/512
run-mlperf--1-r6wbc:62:1110 [0] NCCL INFO Connected all trees
run-mlperf--1-r6wbc:62:1110 [0] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 8/8/512
run-mlperf--1-r6wbc:65:1118 [3] NCCL INFO 24 coll channels, 32 p2p channels, 32 p2p channels per peer
run-mlperf--1-r6wbc:62:1110 [0] NCCL INFO 24 coll channels, 32 p2p channels, 32 p2p channels per peer
run-mlperf--1-r6wbc:64:1115 [2] NCCL INFO Connected all trees
run-mlperf--1-r6wbc:64:1115 [2] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 8/8/512
run-mlperf--1-r6wbc:63:1119 [1] NCCL INFO Connected all trees
run-mlperf--1-r6wbc:63:1119 [1] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 8/8/512
run-mlperf--1-r6wbc:64:1115 [2] NCCL INFO 24 coll channels, 32 p2p channels, 32 p2p channels per peer
run-mlperf--1-r6wbc:63:1119 [1] NCCL INFO 24 coll channels, 32 p2p channels, 32 p2p channels per peer
run-mlperf--1-r6wbc:64:1115 [2] NCCL INFO comm 0x7fd99c008fb0 rank 2 nranks 4 cudaDev 2 busId 47000 - Init COMPLETE
run-mlperf--1-r6wbc:62:1110 [0] NCCL INFO comm 0x7f9804008fb0 rank 0 nranks 4 cudaDev 0 busId 7000 - Init COMPLETE
run-mlperf--1-r6wbc:63:1119 [1] NCCL INFO comm 0x7fd4c0008fb0 rank 1 nranks 4 cudaDev 1 busId f000 - Init COMPLETE
run-mlperf--1-r6wbc:65:1118 [3] NCCL INFO comm 0x7f29ac008fb0 rank 3 nranks 4 cudaDev 3 busId 4e000 - Init COMPLETE
run-mlperf--1-r6wbc:62:62 [0] NCCL INFO Launch mode Parallel
:::MLLOG {"namespace": "", "time_ms": 1639578837545, "event_type": "POINT_IN_TIME", "key": "seed", "value": 2290720000, "metadata": {"file": "tools/train_mlperf.py", "lineno": 716}}
2021-12-15 14:33:57,551 maskrcnn_benchmark INFO: Using 4 GPUs
2021-12-15 14:33:57,551 maskrcnn_benchmark INFO: Namespace(config_file='configs/e2e_mask_rcnn_R_50_FPN_1x.yaml', distributed=True, local_rank=0, opts=['DTYPE', 'float16', 'PATHS_CATALOG', 'maskrcnn_benchmark/config/paths_catalog_dbcluster.py', 'MODEL.WEIGHT', '/data/coco2017/models/R-50.pkl', 'DISABLE_REDUCED_LOGGING', 'True', 'SOLVER.BASE_LR', '0.12', 'SOLVER.WARMUP_FACTOR', '0.000192', 'SOLVER.WARMUP_ITERS', '625', 'SOLVER.WARMUP_METHOD', 'mlperf_linear', 'SOLVER.STEPS', '(12000,16000)', 'SOLVER.IMS_PER_BATCH', '96', 'TEST.IMS_PER_BATCH', '96', 'MODEL.RPN.FPN_POST_NMS_TOP_N_TRAIN', '12000', 'MODEL.RPN.FPN_POST_NMS_TOP_N_PER_IMAGE', 'False', 'NHWC', 'True', 'MODEL.RESNETS.FIRST_TRANS_FUNC', 'FastBottleneckWithFixedBatchNorm', 'MODEL.RESNETS.TRANS_FUNC', 'FastBottleneckWithFixedBatchNorm', 'SOLVER.MAX_ITER', '40000', 'DATALOADER.DALI', 'False', 'DATALOADER.DALI_ON_GPU', 'False', 'DATALOADER.CACHE_EVAL_IMAGES', 'True', 'EVAL_SEGM_NUMPROCS', '10', 'USE_CUDA_GRAPH', 'True', 'EVAL_MASK_VIRTUAL_PASTE', 'True', 'MODEL.BACKBONE.INCLUDE_RPN_HEAD', 'True', 'DATALOADER.NUM_WORKERS', '1', 'PRECOMPUTE_RPN_CONSTANT_TENSORS', 'True', 'DATALOADER.HYBRID', 'True'], seed=2290720000)
2021-12-15 14:33:57,552 maskrcnn_benchmark INFO: Worker 0: Setting seed 447639731
2021-12-15 14:33:57,552 maskrcnn_benchmark INFO: Collecting env info (might take some time)
/opt/conda/lib/python3.8/site-packages/torch/nn/modules/conv.py:1092: UserWarning: _ConvTransposeMixin is a deprecated internal class. Please consider using public APIs.
  warnings.warn(
[(800, 1344), (1344, 800)]
USE_CUDA_GRAPH :: per_gpu_batch_sizes = [(True, 24), (False, 24)]
/opt/conda/lib/python3.8/site-packages/torch/nn/modules/conv.py:1092: UserWarning: _ConvTransposeMixin is a deprecated internal class. Please consider using public APIs.
  warnings.warn(
[(800, 1344), (1344, 800)]
USE_CUDA_GRAPH :: per_gpu_batch_sizes = [(True, 24), (False, 24)]
2021-12-15 14:34:03,331 maskrcnn_benchmark INFO: 
PyTorch version: 1.10.0a0+3fd9dcf
Is debug build: False
CUDA used to build PyTorch: 11.4
ROCM used to build PyTorch: N/A

OS: Ubuntu 20.04.3 LTS (x86_64)
GCC version: (Ubuntu 9.3.0-17ubuntu1~20.04) 9.3.0
Clang version: Could not collect
CMake version: version 3.21.2
Libc version: glibc-2.31

Python version: 3.8.10 | packaged by conda-forge | (default, May 11 2021, 07:01:05)  [GCC 9.3.0] (64-bit runtime)
Python platform: Linux-4.18.0-305.19.1.el8_4.x86_64-x86_64-with-glibc2.10
Is CUDA available: True
CUDA runtime version: 11.4.120
GPU models and configuration: 
GPU 0: NVIDIA A100-SXM4-40GB
GPU 1: NVIDIA A100-SXM4-40GB
GPU 2: NVIDIA A100-SXM4-40GB
GPU 3: NVIDIA A100-SXM4-40GB

Nvidia driver version: 470.82.01
cuDNN version: Probably one of the following:
/usr/lib/x86_64-linux-gnu/libcudnn.so.8.2.4
/usr/lib/x86_64-linux-gnu/libcudnn_adv_infer.so.8.2.4
/usr/lib/x86_64-linux-gnu/libcudnn_adv_train.so.8.2.4
/usr/lib/x86_64-linux-gnu/libcudnn_cnn_infer.so.8.2.4
/usr/lib/x86_64-linux-gnu/libcudnn_cnn_train.so.8.2.4
/usr/lib/x86_64-linux-gnu/libcudnn_ops_infer.so.8.2.4
/usr/lib/x86_64-linux-gnu/libcudnn_ops_train.so.8.2.4
HIP runtime version: N/A
MIOpen runtime version: N/A

Versions of relevant libraries:
[pip3] numpy==1.21.2
[pip3] nvidia-dlprof-pytorch-nvtx==1.5.0
[pip3] pytorch-quantization==2.1.0
[pip3] torch==1.10.0a0+3fd9dcf
[pip3] torchtext==0.11.0a0
[pip3] torchvision==0.11.0a0
[conda] magma-cuda110             2.5.2                         5    local
[conda] mkl                       2019.5                      281    conda-forge
[conda] mkl-include               2019.5                      281    conda-forge
[conda] numpy                     1.21.2           py38he2449b9_0    conda-forge
[conda] nvidia-dlprof-pytorch-nvtx 1.5.0                    pypi_0    pypi
[conda] pytorch-quantization      2.1.0                    pypi_0    pypi
[conda] torch                     1.10.0a0+3fd9dcf          pypi_0    pypi
[conda] torchtext                 0.11.0a0                 pypi_0    pypi
[conda] torchvision               0.11.0a0                 pypi_0    pypi
        Pillow (8.2.0)
2021-12-15 14:34:03,331 maskrcnn_benchmark INFO: Loaded configuration file configs/e2e_mask_rcnn_R_50_FPN_1x.yaml
2021-12-15 14:34:03,331 maskrcnn_benchmark INFO: 
MODEL:
  META_ARCHITECTURE: "GeneralizedRCNN"
  WEIGHT: "catalog://ImageNetPretrained/MSRA/R-50"
  BACKBONE:
    CONV_BODY: "R-50-FPN"
    OUT_CHANNELS: 256
  RPN:
    USE_FPN: True
    ANCHOR_STRIDE: (4, 8, 16, 32, 64)
    PRE_NMS_TOP_N_TRAIN: 2000
    PRE_NMS_TOP_N_TEST: 1000
    POST_NMS_TOP_N_TEST: 1000
    FPN_POST_NMS_TOP_N_TEST: 1000
  ROI_HEADS:
    USE_FPN: True
  ROI_BOX_HEAD:
    POOLER_RESOLUTION: 7
    POOLER_SCALES: (0.25, 0.125, 0.0625, 0.03125)
    POOLER_SAMPLING_RATIO: 2
    FEATURE_EXTRACTOR: "FPN2MLPFeatureExtractor"
    PREDICTOR: "FPNPredictor"
  ROI_MASK_HEAD:
    POOLER_SCALES: (0.25, 0.125, 0.0625, 0.03125)
    FEATURE_EXTRACTOR: "MaskRCNNFPNFeatureExtractor"
    PREDICTOR: "MaskRCNNC4Predictor"
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 2
    RESOLUTION: 28
    SHARE_BOX_FEATURE_EXTRACTOR: False
  MASK_ON: True
DATASETS:
  TRAIN: ("coco_2017_train",)
  TEST: ("coco_2017_val",)
DATALOADER:
  SIZE_DIVISIBILITY: 32
SOLVER:
  BASE_LR: 0.02
  WEIGHT_DECAY: 0.0001
  STEPS: (60000, 80000)
  MAX_ITER: 90000

2021-12-15 14:34:03,332 maskrcnn_benchmark INFO: Running with config:
AMP_VERBOSE: False
CUDA_GRAPH_NUM_SHAPES_PER_ORIENTATION: 1
DATALOADER:
  ALWAYS_PAD_TO_MAX: False
  ASPECT_RATIO_GROUPING: True
  CACHE_EVAL_IMAGES: True
  DALI: False
  DALI_ON_GPU: False
  HYBRID: True
  MAX_ANNOTATIONS_PER_IMAGE: 0
  NUM_WORKERS: 1
  SIZE_DIVISIBILITY: 32
DATASETS:
  TEST: ('coco_2017_val',)
  TRAIN: ('coco_2017_train',)
DEDICATED_EVALUATION_RANKS: 0
DEDICATED_EVALUATION_WAIT_FOR_RESULT_ITERATIONS: 100
DISABLE_LOSS_LOGGING: False
DISABLE_REDUCED_LOGGING: True
DTYPE: float16
DYNAMIC_LOSS_SCALE_WINDOW: 1000
EVAL_MASK_VIRTUAL_PASTE: True
EVAL_SEGM_NUMPROCS: 10
FUSED_SGD_DEBUG_PRINTS: False
INPUT:
  MAX_SIZE_TEST: 1333
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 800
  MIN_SIZE_TRAIN: (800,)
  PIXEL_MEAN: [102.9801, 115.9465, 122.7717]
  PIXEL_STD: [1.0, 1.0, 1.0]
  TO_BGR255: True
MLPERF:
  MIN_BBOX_MAP: 0.377
  MIN_SEGM_MAP: 0.339
MODEL:
  BACKBONE:
    CONV_BODY: R-50-FPN
    FREEZE_CONV_BODY_AT: 2
    INCLUDE_RPN_HEAD: True
    OUT_CHANNELS: 256
    USE_GN: False
  CLS_AGNOSTIC_BBOX_REG: False
  DEVICE: cuda
  FPN:
    USE_GN: False
    USE_RELU: False
  GROUP_NORM:
    DIM_PER_GP: -1
    EPSILON: 1e-05
    NUM_GROUPS: 32
  KEYPOINT_ON: False
  MASK_ON: True
  META_ARCHITECTURE: GeneralizedRCNN
  RESNETS:
    FIRST_TRANS_FUNC: FastBottleneckWithFixedBatchNorm
    NUM_GROUPS: 1
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STEM_FUNC: StemWithFixedBatchNorm
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: True
    TRANS_FUNC: FastBottleneckWithFixedBatchNorm
    WIDTH_PER_GROUP: 64
  RETINANET:
    ANCHOR_SIZES: (32, 64, 128, 256, 512)
    ANCHOR_STRIDES: (8, 16, 32, 64, 128)
    ASPECT_RATIOS: (0.5, 1.0, 2.0)
    BBOX_REG_BETA: 0.11
    BBOX_REG_WEIGHT: 4.0
    BG_IOU_THRESHOLD: 0.4
    FG_IOU_THRESHOLD: 0.5
    INFERENCE_TH: 0.05
    LOSS_ALPHA: 0.25
    LOSS_GAMMA: 2.0
    NMS_TH: 0.4
    NUM_CLASSES: 81
    NUM_CONVS: 4
    OCTAVE: 2.0
    PRE_NMS_TOP_N: 1000
    PRIOR_PROB: 0.01
    SCALES_PER_OCTAVE: 3
    STRADDLE_THRESH: 0
    USE_C5: True
  RETINANET_ON: False
  ROI_BOX_HEAD:
    CONV_HEAD_DIM: 256
    DILATION: 1
    FEATURE_EXTRACTOR: FPN2MLPFeatureExtractor
    MLP_HEAD_DIM: 1024
    NUM_CLASSES: 81
    NUM_STACKED_CONVS: 4
    POOLER_RESOLUTION: 7
    POOLER_SAMPLING_RATIO: 2
    POOLER_SCALES: (0.25, 0.125, 0.0625, 0.03125)
    PREDICTOR: FPNPredictor
    USE_GN: False
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 512
    BBOX_REG_WEIGHTS: (10.0, 10.0, 5.0, 5.0)
    BG_IOU_THRESHOLD: 0.5
    DETECTIONS_PER_IMG: 100
    FG_IOU_THRESHOLD: 0.5
    NMS: 0.5
    POSITIVE_FRACTION: 0.25
    SCORE_THRESH: 0.05
    USE_FPN: True
  ROI_KEYPOINT_HEAD:
    CONV_LAYERS: (512, 512, 512, 512, 512, 512, 512, 512)
    FEATURE_EXTRACTOR: KeypointRCNNFeatureExtractor
    MLP_HEAD_DIM: 1024
    NUM_CLASSES: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_SCALES: (0.0625,)
    PREDICTOR: KeypointRCNNPredictor
    RESOLUTION: 14
    SHARE_BOX_FEATURE_EXTRACTOR: True
  ROI_MASK_HEAD:
    CONV_LAYERS: (256, 256, 256, 256)
    DILATION: 1
    FEATURE_EXTRACTOR: MaskRCNNFPNFeatureExtractor
    MLP_HEAD_DIM: 1024
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 2
    POOLER_SCALES: (0.25, 0.125, 0.0625, 0.03125)
    POSTPROCESS_MASKS: False
    POSTPROCESS_MASKS_THRESHOLD: 0.5
    PREDICTOR: MaskRCNNC4Predictor
    RESOLUTION: 28
    SHARE_BOX_FEATURE_EXTRACTOR: False
    USE_GN: False
  RPN:
    ANCHOR_SIZES: (32, 64, 128, 256, 512)
    ANCHOR_STRIDE: (4, 8, 16, 32, 64)
    ASPECT_RATIOS: (0.5, 1.0, 2.0)
    BATCH_SIZE_PER_IMAGE: 256
    BG_IOU_THRESHOLD: 0.3
    FG_IOU_THRESHOLD: 0.7
    FPN_POST_NMS_TOP_N_PER_IMAGE: False
    FPN_POST_NMS_TOP_N_TEST: 1000
    FPN_POST_NMS_TOP_N_TRAIN: 12000
    MIN_SIZE: 0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOP_N_TEST: 1000
    POST_NMS_TOP_N_TRAIN: 2000
    PRE_NMS_TOP_N_TEST: 1000
    PRE_NMS_TOP_N_TRAIN: 2000
    RPN_HEAD: SingleConvRPNHead
    STRADDLE_THRESH: 0
    USE_FPN: True
  RPN_ONLY: False
  WEIGHT: /data/coco2017/models/R-50.pkl
NHWC: True
OUTPUT_DIR: .
PATHS_CATALOG: maskrcnn_benchmark/config/paths_catalog_dbcluster.py
PER_EPOCH_EVAL: True
PRECOMPUTE_RPN_CONSTANT_TENSORS: True
SAVE_CHECKPOINTS: False
SOLVER:
  BASE_LR: 0.12
  BIAS_LR_FACTOR: 2
  CHECKPOINT_PERIOD: 2500
  GAMMA: 0.1
  IMS_PER_BATCH: 96
  MAX_ITER: 40000
  MOMENTUM: 0.9
  STEPS: (12000, 16000)
  WARMUP_FACTOR: 0.000192
  WARMUP_ITERS: 625
  WARMUP_METHOD: mlperf_linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: 0
SYNCFREE_ROI: True
TEST:
  DETECTIONS_PER_IMG: 100
  EXPECTED_RESULTS: []
  EXPECTED_RESULTS_SIGMA_TOL: 4
  IMS_PER_BATCH: 96
USE_CUDA_GRAPH: True
:::MLLOG {"namespace": "", "time_ms": 1639578843333, "event_type": "POINT_IN_TIME", "key": "d_batch_size", "value": 24.0, "metadata": {"file": "tools/train_mlperf.py", "lineno": 759}}
:::MLLOG {"namespace": "", "time_ms": 1639578843333, "event_type": "POINT_IN_TIME", "key": "global_batch_size", "value": 96, "metadata": {"file": "tools/train_mlperf.py", "lineno": 353}}
:::MLLOG {"namespace": "", "time_ms": 1639578843333, "event_type": "POINT_IN_TIME", "key": "num_image_candidates", "value": 12000, "metadata": {"file": "tools/train_mlperf.py", "lineno": 354}}
:::MLLOG {"namespace": "", "time_ms": 1639578843333, "event_type": "POINT_IN_TIME", "key": "gradient_accumulation_steps", "value": 1, "metadata": {"file": "tools/train_mlperf.py", "lineno": 355}}
:::MLLOG {"namespace": "", "time_ms": 1639578843693, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/object_detection/maskrcnn_benchmark/modeling/backbone/fpn.py", "lineno": 44, "tensor": "FPN_inner_block1"}}
:::MLLOG {"namespace": "", "time_ms": 1639578843701, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/object_detection/maskrcnn_benchmark/modeling/backbone/fpn.py", "lineno": 47, "tensor": "FPN_layer_block1"}}
:::MLLOG {"namespace": "", "time_ms": 1639578843702, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/object_detection/maskrcnn_benchmark/modeling/backbone/fpn.py", "lineno": 44, "tensor": "FPN_inner_block2"}}
:::MLLOG {"namespace": "", "time_ms": 1639578843709, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/object_detection/maskrcnn_benchmark/modeling/backbone/fpn.py", "lineno": 47, "tensor": "FPN_layer_block2"}}
:::MLLOG {"namespace": "", "time_ms": 1639578843712, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/object_detection/maskrcnn_benchmark/modeling/backbone/fpn.py", "lineno": 44, "tensor": "FPN_inner_block3"}}
:::MLLOG {"namespace": "", "time_ms": 1639578843720, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/object_detection/maskrcnn_benchmark/modeling/backbone/fpn.py", "lineno": 47, "tensor": "FPN_layer_block3"}}
:::MLLOG {"namespace": "", "time_ms": 1639578843724, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/object_detection/maskrcnn_benchmark/modeling/backbone/fpn.py", "lineno": 44, "tensor": "FPN_inner_block4"}}
:::MLLOG {"namespace": "", "time_ms": 1639578843732, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/object_detection/maskrcnn_benchmark/modeling/backbone/fpn.py", "lineno": 47, "tensor": "FPN_layer_block4"}}
:::MLLOG {"namespace": "", "time_ms": 1639578843740, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/object_detection/maskrcnn_benchmark/modeling/rpn/rpn.py", "lineno": 44, "tensor": "RPNHead_conv"}}
:::MLLOG {"namespace": "", "time_ms": 1639578843740, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/object_detection/maskrcnn_benchmark/modeling/rpn/rpn.py", "lineno": 45, "tensor": "RPNHead_cls"}}
:::MLLOG {"namespace": "", "time_ms": 1639578843740, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/object_detection/maskrcnn_benchmark/modeling/rpn/rpn.py", "lineno": 46, "tensor": "RPNHead_bbox"}}
:::MLLOG {"namespace": "", "time_ms": 1639578843863, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/object_detection/maskrcnn_benchmark/modeling/roi_heads/box_head/roi_box_feature_extractors.py", "lineno": 83, "tensor": "ROI_BOX_FEATURE_EXTRACTOR_fc6"}}
:::MLLOG {"namespace": "", "time_ms": 1639578843875, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/object_detection/maskrcnn_benchmark/modeling/roi_heads/box_head/roi_box_feature_extractors.py", "lineno": 86, "tensor": "ROI_BOX_FEATURE_EXTRACTOR_fc7"}}
:::MLLOG {"namespace": "", "time_ms": 1639578843880, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/object_detection/maskrcnn_benchmark/modeling/roi_heads/box_head/roi_box_predictors.py", "lineno": 50, "tensor": "ROI_BOX_PREDICTOR_cls"}}
:::MLLOG {"namespace": "", "time_ms": 1639578843882, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/object_detection/maskrcnn_benchmark/modeling/roi_heads/box_head/roi_box_predictors.py", "lineno": 52, "tensor": "ROI_BOX_PREDICTOR_bbox"}}
:::MLLOG {"namespace": "", "time_ms": 1639578843893, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/object_detection/maskrcnn_benchmark/modeling/roi_heads/mask_head/roi_mask_feature_extractors.py", "lineno": 52, "tensor": "ROI_MASK_FEATURE_EXTRACTOR_fcn1"}}
:::MLLOG {"namespace": "", "time_ms": 1639578843902, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/object_detection/maskrcnn_benchmark/modeling/roi_heads/mask_head/roi_mask_feature_extractors.py", "lineno": 52, "tensor": "ROI_MASK_FEATURE_EXTRACTOR_fcn2"}}
:::MLLOG {"namespace": "", "time_ms": 1639578843910, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/object_detection/maskrcnn_benchmark/modeling/roi_heads/mask_head/roi_mask_feature_extractors.py", "lineno": 52, "tensor": "ROI_MASK_FEATURE_EXTRACTOR_fcn3"}}
:::MLLOG {"namespace": "", "time_ms": 1639578843918, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/object_detection/maskrcnn_benchmark/modeling/roi_heads/mask_head/roi_mask_feature_extractors.py", "lineno": 52, "tensor": "ROI_MASK_FEATURE_EXTRACTOR_fcn4"}}
/opt/conda/lib/python3.8/site-packages/torch/nn/modules/conv.py:1092: UserWarning: _ConvTransposeMixin is a deprecated internal class. Please consider using public APIs.
  warnings.warn(
:::MLLOG {"namespace": "", "time_ms": 1639578843922, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/object_detection/maskrcnn_benchmark/modeling/roi_heads/mask_head/roi_mask_predictors.py", "lineno": 42, "tensor": "ROI_MASK_PREDICTOR_fcn5"}}
:::MLLOG {"namespace": "", "time_ms": 1639578843922, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/object_detection/maskrcnn_benchmark/modeling/roi_heads/mask_head/roi_mask_predictors.py", "lineno": 43, "tensor": "ROI_MASK_PREDICTOR_fcn_logits"}}
[(800, 1344), (1344, 800)]
USE_CUDA_GRAPH :: per_gpu_batch_sizes = [(True, 24), (False, 24)]
/opt/conda/lib/python3.8/site-packages/torch/nn/modules/conv.py:1092: UserWarning: _ConvTransposeMixin is a deprecated internal class. Please consider using public APIs.
  warnings.warn(
[(800, 1344), (1344, 800)]
USE_CUDA_GRAPH :: per_gpu_batch_sizes = [(True, 24), (False, 24)]
Graphing

Traceback (most recent call last):
  File "tools/train_mlperf.py", line 772, in <module>
    main()
  File "tools/train_mlperf.py", line 761, in main
    model, success = train(cfg, rank, world_size, args.distributed, random_number_generator, seed=master_seed)
  File "tools/train_mlperf.py", line 421, in train
    model.graphable, pool_id = graph(model.graphable,
  File "/workspace/object_detection/function.py", line 166, in graph
    return func_or_module, fwd_graph.pool()
RuntimeError: Called CUDAGraph::pool() without a preceding successful capture.
Graphing

Traceback (most recent call last):
  File "tools/train_mlperf.py", line 772, in <module>
    main()
  File "tools/train_mlperf.py", line 761, in main
    model, success = train(cfg, rank, world_size, args.distributed, random_number_generator, seed=master_seed)
  File "tools/train_mlperf.py", line 421, in train
    model.graphable, pool_id = graph(model.graphable,
  File "/workspace/object_detection/function.py", line 166, in graph
    return func_or_module, fwd_graph.pool()
RuntimeError: Called CUDAGraph::pool() without a preceding successful capture.
Graphing

Graphing

Traceback (most recent call last):
  File "tools/train_mlperf.py", line 772, in <module>
    main()
  File "tools/train_mlperf.py", line 761, in main
    model, success = train(cfg, rank, world_size, args.distributed, random_number_generator, seed=master_seed)
  File "tools/train_mlperf.py", line 421, in train
    model.graphable, pool_id = graph(model.graphable,
  File "/workspace/object_detection/function.py", line 166, in graph
    return func_or_module, fwd_graph.pool()
RuntimeError: Called CUDAGraph::pool() without a preceding successful capture.
Traceback (most recent call last):
  File "tools/train_mlperf.py", line 772, in <module>
    main()
  File "tools/train_mlperf.py", line 761, in main
    model, success = train(cfg, rank, world_size, args.distributed, random_number_generator, seed=master_seed)
  File "tools/train_mlperf.py", line 421, in train
    model.graphable, pool_id = graph(model.graphable,
  File "/workspace/object_detection/function.py", line 166, in graph
    return func_or_module, fwd_graph.pool()
RuntimeError: Called CUDAGraph::pool() without a preceding successful capture.
++ date
Wed Dec 15 14:35:29 UTC 2021
failed
++ echo failed
++ exit 1
