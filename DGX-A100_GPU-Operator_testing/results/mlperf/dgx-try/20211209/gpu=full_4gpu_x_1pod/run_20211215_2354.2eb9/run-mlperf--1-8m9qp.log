8<--8<--8<--8<--
GPU 0: NVIDIA A100-SXM4-40GB (UUID: GPU-4dd97325-7fe6-abf1-d6a9-ba746fe0fdab)
GPU 1: NVIDIA A100-SXM4-40GB (UUID: GPU-9e13f17f-a213-eb38-9a9c-0b2a540e4908)
GPU 2: NVIDIA A100-SXM4-40GB (UUID: GPU-1ae21a3c-f40b-77a7-002f-4b0b52b05f5b)
GPU 3: NVIDIA A100-SXM4-40GB (UUID: GPU-eeb0f073-2f03-6035-72a3-7b1ac76c5a72)
8<--8<--8<--8<--
++ nvidia-smi -L
++ grep 'UUID: MIG-'
++ wc -l
++ true
+ NB_GPUS=0
+ [[ 0 == 0 ]]
++ nvidia-smi -L
++ grep 'UUID: GPU'
++ cut '-d ' -f6
++ cut '-d)' -f1
+ ALL_GPUS='GPU-4dd97325-7fe6-abf1-d6a9-ba746fe0fdab
GPU-9e13f17f-a213-eb38-9a9c-0b2a540e4908
GPU-1ae21a3c-f40b-77a7-002f-4b0b52b05f5b
GPU-eeb0f073-2f03-6035-72a3-7b1ac76c5a72'
++ nvidia-smi -L
++ grep 'UUID: GPU'
++ wc -l
+ NB_GPUS=4
+ MIG_MODE=0
+ [[ full != \f\u\l\l ]]
+ echo 'No MIG GPU available, using the full GPUs (GPU-4dd97325-7fe6-abf1-d6a9-ba746fe0fdab
GPU-9e13f17f-a213-eb38-9a9c-0b2a540e4908
GPU-1ae21a3c-f40b-77a7-002f-4b0b52b05f5b
No MIG GPU available, using the full GPUs (GPU-4dd97325-7fe6-abf1-d6a9-ba746fe0fdab
GPU-9e13f17f-a213-eb38-9a9c-0b2a540e4908
GPU-1ae21a3c-f40b-77a7-002f-4b0b52b05f5b
GPU-eeb0f073-2f03-6035-72a3-7b1ac76c5a72).
GPU-eeb0f073-2f03-6035-72a3-7b1ac76c5a72).'
+ [[ 4 == 0 ]]
+ [[ 4 != 4 ]]
++ date +%s
+ start=1639608879
++ date '+%Y-%m-%d %r'
+ start_fmt='2021-12-15 10:54:39 PM'
+ echo 'STARTING TIMING RUN AT 2021-12-15 10:54:39 PM GPU: 4 x full x 1 Pods'
STARTING TIMING RUN AT 2021-12-15 10:54:39 PM GPU: 4 x full x 1 Pods
+ set -x
+ export NCCL_DEBUG=INFO
+ NCCL_DEBUG=INFO
running benchmark
+ echo 'running benchmark'
+ export DATASET_DIR=/data/coco2017
+ DATASET_DIR=/data/coco2017
+ export TORCH_HOME=/data/coco2017/torchvision
+ TORCH_HOME=/data/coco2017/torchvision
+ '[' '!' -f /data/coco2017/annotations/bbox_only_instances_val2017.json ']'
+ '[' '!' -f /data/coco2017/annotations/bbox_only_instances_train2017.json ']'
+ [[ maskrcnn == \m\a\s\k\r\c\n\n ]]
Setting up the Mask RCNN benchmark...
+ echo 'Setting up the Mask RCNN benchmark...'
+ NEXP=1
+ source config_DGXA100.sh
++ : False
++ : True
++ : True
++ : 10
++ : True
++ : True
++ : True
++ : 1
++ : True
++ : 40000
++ export BATCHSIZE=12
++ BATCHSIZE=12
++ export EXTRA_PARAMS=
++ EXTRA_PARAMS=
++ export 'EXTRA_CONFIG=SOLVER.BASE_LR 0.12 SOLVER.WARMUP_FACTOR 0.000192 SOLVER.WARMUP_ITERS 625 SOLVER.WARMUP_METHOD mlperf_linear SOLVER.STEPS (12000,16000) SOLVER.IMS_PER_BATCH 96 TEST.IMS_PER_BATCH 96 MODEL.RPN.FPN_POST_NMS_TOP_N_TRAIN 12000 MODEL.RPN.FPN_POST_NMS_TOP_N_PER_IMAGE False NHWC True MODEL.RESNETS.FIRST_TRANS_FUNC FastBottleneckWithFixedBatchNorm MODEL.RESNETS.TRANS_FUNC FastBottleneckWithFixedBatchNorm'
++ EXTRA_CONFIG='SOLVER.BASE_LR 0.12 SOLVER.WARMUP_FACTOR 0.000192 SOLVER.WARMUP_ITERS 625 SOLVER.WARMUP_METHOD mlperf_linear SOLVER.STEPS (12000,16000) SOLVER.IMS_PER_BATCH 96 TEST.IMS_PER_BATCH 96 MODEL.RPN.FPN_POST_NMS_TOP_N_TRAIN 12000 MODEL.RPN.FPN_POST_NMS_TOP_N_PER_IMAGE False NHWC True MODEL.RESNETS.FIRST_TRANS_FUNC FastBottleneckWithFixedBatchNorm MODEL.RESNETS.TRANS_FUNC FastBottleneckWithFixedBatchNorm'
++ export 'EXTRA_CONFIG=SOLVER.BASE_LR 0.12 SOLVER.WARMUP_FACTOR 0.000192 SOLVER.WARMUP_ITERS 625 SOLVER.WARMUP_METHOD mlperf_linear SOLVER.STEPS (12000,16000) SOLVER.IMS_PER_BATCH 96 TEST.IMS_PER_BATCH 96 MODEL.RPN.FPN_POST_NMS_TOP_N_TRAIN 12000 MODEL.RPN.FPN_POST_NMS_TOP_N_PER_IMAGE False NHWC True MODEL.RESNETS.FIRST_TRANS_FUNC FastBottleneckWithFixedBatchNorm MODEL.RESNETS.TRANS_FUNC FastBottleneckWithFixedBatchNorm SOLVER.MAX_ITER 40000 DATALOADER.DALI False DATALOADER.DALI_ON_GPU False DATALOADER.CACHE_EVAL_IMAGES True EVAL_SEGM_NUMPROCS 10 USE_CUDA_GRAPH True EVAL_MASK_VIRTUAL_PASTE True MODEL.BACKBONE.INCLUDE_RPN_HEAD True DATALOADER.NUM_WORKERS 1 PRECOMPUTE_RPN_CONSTANT_TENSORS True DATALOADER.HYBRID True'
++ EXTRA_CONFIG='SOLVER.BASE_LR 0.12 SOLVER.WARMUP_FACTOR 0.000192 SOLVER.WARMUP_ITERS 625 SOLVER.WARMUP_METHOD mlperf_linear SOLVER.STEPS (12000,16000) SOLVER.IMS_PER_BATCH 96 TEST.IMS_PER_BATCH 96 MODEL.RPN.FPN_POST_NMS_TOP_N_TRAIN 12000 MODEL.RPN.FPN_POST_NMS_TOP_N_PER_IMAGE False NHWC True MODEL.RESNETS.FIRST_TRANS_FUNC FastBottleneckWithFixedBatchNorm MODEL.RESNETS.TRANS_FUNC FastBottleneckWithFixedBatchNorm SOLVER.MAX_ITER 40000 DATALOADER.DALI False DATALOADER.DALI_ON_GPU False DATALOADER.CACHE_EVAL_IMAGES True EVAL_SEGM_NUMPROCS 10 USE_CUDA_GRAPH True EVAL_MASK_VIRTUAL_PASTE True MODEL.BACKBONE.INCLUDE_RPN_HEAD True DATALOADER.NUM_WORKERS 1 PRECOMPUTE_RPN_CONSTANT_TENSORS True DATALOADER.HYBRID True'
++ export DGXNNODES=1
++ DGXNNODES=1
+++ sed 's/^config_//'
+++ sed 's/\.sh$//'
++++ readlink -f config_DGXA100.sh
+++ basename /workspace/object_detection/config_DGXA100.sh
++ export DGXSYSTEM=DGXA100
++ DGXSYSTEM=DGXA100
++ WALLTIME_MINUTES=100
++ export WALLTIME=100
++ WALLTIME=100
++ export DGXNGPU=8
++ DGXNGPU=8
++ export DGXSOCKETCORES=48
++ DGXSOCKETCORES=48
++ export DGXNSOCKET=2
++ DGXNSOCKET=2
++ export DGXHT=1
++ DGXHT=1
+ DGXNSOCKET=1
+ DGXSOCKETCORES=48
+ [[ 0 == \1 ]]
+ DGXNGPU=4
+ echo 'Running in multi-gpu mode.'
Running in multi-gpu mode.
+ declare -a CMD
+ CMD=('python' '-u' '-m' 'bind_launch' "--nsockets_per_node=${DGXNSOCKET}" "--ncores_per_socket=${DGXSOCKETCORES}" "--nproc_per_node=${DGXNGPU}")
+ declare -a ARGS
Patching 'bind_launch.py' to err-exit on failure ...
+ echo 'Patching '\''bind_launch.py'\'' to err-exit on failure ...'
+ sed 's/process.wait()$/if process.wait(): sys.exit(1)/' -i bind_launch.py
+ [[ maskrcnn == \s\s\d ]]
+ [[ maskrcnn == \m\a\s\k\r\c\n\n ]]
+ echo 'Setting up the Mask RCNN benchmark...'
Setting up the Mask RCNN benchmark...
+ sed 's/torch.set_num_threads(1)$/import time, sys; time.sleep(int(sys.argv[1].split("=")[-1]));torch.set_num_threads(1);/' -i tools/train_mlperf.py
+ MODEL=/data/coco2017/models/R-50.pkl
+ [[ -f /data/coco2017/models/R-50.pkl ]]
++ cat /data/coco2017/models/R-50.pkl
++ md5sum
+ sum='6652b4a9c782d82bb3d42118be74d79b  -'
+ [[ 6652b4a9c782d82bb3d42118be74d79b  - != \6\6\5\2\b\4\a\9\c\7\8\2\d\8\2\b\b\3\d\4\2\1\1\8\b\e\7\4\d\7\9\b\ \ \- ]]
+ [[ ! -f /data/coco2017/models/R-50.pkl ]]
+ ln -sf /data/coco2017 /coco
+ ARGS=(tools/train_mlperf.py ${EXTRA_PARAMS} --config-file 'configs/e2e_mask_rcnn_R_50_FPN_1x.yaml' DTYPE 'float16' PATHS_CATALOG 'maskrcnn_benchmark/config/paths_catalog_dbcluster.py' MODEL.WEIGHT "$MODEL" DISABLE_REDUCED_LOGGING True ${EXTRA_CONFIG})
+ [[ run == \d\r\y ]]
+ trap 'date; echo failed; exit 1' ERR
+ [[ n != \y ]]
+ SYNC_DIR=/data/coco2017/sync
+ mkdir -p /data/coco2017/sync
+ for sync_f in "$SYNC_DIR/"*
+ [[ /data/coco2017/sync/2021-12-15_23-46-16 != \/\d\a\t\a\/\c\o\c\o\2\0\1\7\/\s\y\n\c\/\2\0\2\1\-\1\2\-\1\5\_\2\3\-\5\4\-\1\9 ]]
+ rm -f /data/coco2017/sync/2021-12-15_23-46-16
+ set +x
Wed Dec 15 22:54:39 UTC 2021 Waiting for all the 1 Pods to start ...
Adding run-mlperf--1-8m9qp to the sync file ...
Wed Dec 15 22:54:39 UTC 2021 All the 1 Pods are running, launch the GPU workload.
+ nvidia-smi -L
GPU 0: NVIDIA A100-SXM4-40GB (UUID: GPU-4dd97325-7fe6-abf1-d6a9-ba746fe0fdab)
GPU 1: NVIDIA A100-SXM4-40GB (UUID: GPU-9e13f17f-a213-eb38-9a9c-0b2a540e4908)
GPU 2: NVIDIA A100-SXM4-40GB (UUID: GPU-1ae21a3c-f40b-77a7-002f-4b0b52b05f5b)
GPU 3: NVIDIA A100-SXM4-40GB (UUID: GPU-eeb0f073-2f03-6035-72a3-7b1ac76c5a72)
+ [[ 0 == 1 ]]
+ dest=/tmp/benchmark_all.log
+ [[ 0 == 1 ]]
Running on all the 4 GPUs 
+ echo 'Running on all the 4 GPUs '
+ python -u -m bind_launch --nsockets_per_node=1 --ncores_per_socket=48 --nproc_per_node=4 tools/train_mlperf.py --config-file configs/e2e_mask_rcnn_R_50_FPN_1x.yaml DTYPE float16 PATHS_CATALOG maskrcnn_benchmark/config/paths_catalog_dbcluster.py MODEL.WEIGHT /data/coco2017/models/R-50.pkl DISABLE_REDUCED_LOGGING True SOLVER.BASE_LR 0.12 SOLVER.WARMUP_FACTOR 0.000192 SOLVER.WARMUP_ITERS 625 SOLVER.WARMUP_METHOD mlperf_linear SOLVER.STEPS '(12000,16000)' SOLVER.IMS_PER_BATCH 96 TEST.IMS_PER_BATCH 96 MODEL.RPN.FPN_POST_NMS_TOP_N_TRAIN 12000 MODEL.RPN.FPN_POST_NMS_TOP_N_PER_IMAGE False NHWC True MODEL.RESNETS.FIRST_TRANS_FUNC FastBottleneckWithFixedBatchNorm MODEL.RESNETS.TRANS_FUNC FastBottleneckWithFixedBatchNorm SOLVER.MAX_ITER 40000 DATALOADER.DALI False DATALOADER.DALI_ON_GPU False DATALOADER.CACHE_EVAL_IMAGES True EVAL_SEGM_NUMPROCS 10 USE_CUDA_GRAPH True EVAL_MASK_VIRTUAL_PASTE True MODEL.BACKBONE.INCLUDE_RPN_HEAD True DATALOADER.NUM_WORKERS 1 PRECOMPUTE_RPN_CONSTANT_TENSORS True DATALOADER.HYBRID True
+ tee -a /tmp/benchmark_all.log
:::MLLOG {"namespace": "", "time_ms": 1639608881620, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "tools/train_mlperf.py", "lineno": 411}}
:::MLLOG {"namespace": "", "time_ms": 1639608882629, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "tools/train_mlperf.py", "lineno": 411}}
:::MLLOG {"namespace": "", "time_ms": 1639608883648, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "tools/train_mlperf.py", "lineno": 411}}
:::MLLOG {"namespace": "", "time_ms": 1639608884644, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "tools/train_mlperf.py", "lineno": 411}}
run-mlperf--1-8m9qp:61:61 [0] NCCL INFO Bootstrap : Using eth0:10.128.0.183<0>
run-mlperf--1-8m9qp:61:61 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
run-mlperf--1-8m9qp:61:61 [0] NCCL INFO P2P plugin IBext
run-mlperf--1-8m9qp:61:61 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/RoCE [1]mlx5_7:1/RoCE ; OOB eth0:10.128.0.183<0>
run-mlperf--1-8m9qp:61:61 [0] NCCL INFO Using network IBext
NCCL version 2.11.4+cuda11.4
run-mlperf--1-8m9qp:62:62 [1] NCCL INFO Bootstrap : Using eth0:10.128.0.183<0>
run-mlperf--1-8m9qp:62:62 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
run-mlperf--1-8m9qp:62:62 [1] NCCL INFO P2P plugin IBext
run-mlperf--1-8m9qp:63:63 [2] NCCL INFO Bootstrap : Using eth0:10.128.0.183<0>
run-mlperf--1-8m9qp:64:64 [3] NCCL INFO Bootstrap : Using eth0:10.128.0.183<0>
run-mlperf--1-8m9qp:63:63 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
run-mlperf--1-8m9qp:63:63 [2] NCCL INFO P2P plugin IBext
run-mlperf--1-8m9qp:64:64 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
run-mlperf--1-8m9qp:64:64 [3] NCCL INFO P2P plugin IBext
run-mlperf--1-8m9qp:62:62 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/RoCE [1]mlx5_7:1/RoCE ; OOB eth0:10.128.0.183<0>
run-mlperf--1-8m9qp:62:62 [1] NCCL INFO Using network IBext
run-mlperf--1-8m9qp:63:63 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/RoCE [1]mlx5_7:1/RoCE ; OOB eth0:10.128.0.183<0>
run-mlperf--1-8m9qp:63:63 [2] NCCL INFO Using network IBext
run-mlperf--1-8m9qp:64:64 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/RoCE [1]mlx5_7:1/RoCE ; OOB eth0:10.128.0.183<0>
run-mlperf--1-8m9qp:64:64 [3] NCCL INFO Using network IBext
run-mlperf--1-8m9qp:61:1109 [0] NCCL INFO Channel 00/24 :    0   1   2   3
run-mlperf--1-8m9qp:61:1109 [0] NCCL INFO Channel 01/24 :    0   1   2   3
run-mlperf--1-8m9qp:61:1109 [0] NCCL INFO Channel 02/24 :    0   1   2   3
run-mlperf--1-8m9qp:61:1109 [0] NCCL INFO Channel 03/24 :    0   1   2   3
run-mlperf--1-8m9qp:61:1109 [0] NCCL INFO Channel 04/24 :    0   1   2   3
run-mlperf--1-8m9qp:61:1109 [0] NCCL INFO Channel 05/24 :    0   1   2   3
run-mlperf--1-8m9qp:61:1109 [0] NCCL INFO Channel 06/24 :    0   1   2   3
run-mlperf--1-8m9qp:61:1109 [0] NCCL INFO Channel 07/24 :    0   1   2   3
run-mlperf--1-8m9qp:61:1109 [0] NCCL INFO Channel 08/24 :    0   1   2   3
run-mlperf--1-8m9qp:61:1109 [0] NCCL INFO Channel 09/24 :    0   1   2   3
run-mlperf--1-8m9qp:61:1109 [0] NCCL INFO Channel 10/24 :    0   1   2   3
run-mlperf--1-8m9qp:61:1109 [0] NCCL INFO Channel 11/24 :    0   1   2   3
run-mlperf--1-8m9qp:61:1109 [0] NCCL INFO Channel 12/24 :    0   1   2   3
run-mlperf--1-8m9qp:61:1109 [0] NCCL INFO Channel 13/24 :    0   1   2   3
run-mlperf--1-8m9qp:64:1118 [3] NCCL INFO Trees [0] -1/-1/-1->3->2 [1] -1/-1/-1->3->2 [2] -1/-1/-1->3->2 [3] -1/-1/-1->3->2 [4] -1/-1/-1->3->2 [5] -1/-1/-1->3->2 [6] -1/-1/-1->3->2 [7] -1/-1/-1->3->2 [8] -1/-1/-1->3->2 [9] -1/-1/-1->3->2 [10] -1/-1/-1->3->2 [11] -1/-1/-1->3->2 [12] -1/-1/-1->3->2 [13] -1/-1/-1->3->2 [14] -1/-1/-1->3->2 [15] -1/-1/-1->3->2 [16] -1/-1/-1->3->2 [17] -1/-1/-1->3->2 [18] -1/-1/-1->3->2 [19] -1/-1/-1->3->2 [20] -1/-1/-1->3->2 [21] -1/-1/-1->3->2 [22] -1/-1/-1->3->2 [23] -1/-1/-1->3->2
run-mlperf--1-8m9qp:61:1109 [0] NCCL INFO Channel 14/24 :    0   1   2   3
run-mlperf--1-8m9qp:61:1109 [0] NCCL INFO Channel 15/24 :    0   1   2   3
run-mlperf--1-8m9qp:61:1109 [0] NCCL INFO Channel 16/24 :    0   1   2   3
run-mlperf--1-8m9qp:61:1109 [0] NCCL INFO Channel 17/24 :    0   1   2   3
run-mlperf--1-8m9qp:63:1117 [2] NCCL INFO Trees [0] 3/-1/-1->2->1 [1] 3/-1/-1->2->1 [2] 3/-1/-1->2->1 [3] 3/-1/-1->2->1 [4] 3/-1/-1->2->1 [5] 3/-1/-1->2->1 [6] 3/-1/-1->2->1 [7] 3/-1/-1->2->1 [8] 3/-1/-1->2->1 [9] 3/-1/-1->2->1 [10] 3/-1/-1->2->1 [11] 3/-1/-1->2->1 [12] 3/-1/-1->2->1 [13] 3/-1/-1->2->1 [14] 3/-1/-1->2->1 [15] 3/-1/-1->2->1 [16] 3/-1/-1->2->1 [17] 3/-1/-1->2->1 [18] 3/-1/-1->2->1 [19] 3/-1/-1->2->1 [20] 3/-1/-1->2->1 [21] 3/-1/-1->2->1 [22] 3/-1/-1->2->1 [23] 3/-1/-1->2->1
run-mlperf--1-8m9qp:61:1109 [0] NCCL INFO Channel 18/24 :    0   1   2   3
run-mlperf--1-8m9qp:61:1109 [0] NCCL INFO Channel 19/24 :    0   1   2   3
run-mlperf--1-8m9qp:61:1109 [0] NCCL INFO Channel 20/24 :    0   1   2   3
run-mlperf--1-8m9qp:61:1109 [0] NCCL INFO Channel 21/24 :    0   1   2   3
run-mlperf--1-8m9qp:61:1109 [0] NCCL INFO Channel 22/24 :    0   1   2   3
run-mlperf--1-8m9qp:63:1117 [2] NCCL INFO Setting affinity for GPU 2 to ff000000
run-mlperf--1-8m9qp:61:1109 [0] NCCL INFO Channel 23/24 :    0   1   2   3
run-mlperf--1-8m9qp:62:1114 [1] NCCL INFO Trees [0] 2/-1/-1->1->0 [1] 2/-1/-1->1->0 [2] 2/-1/-1->1->0 [3] 2/-1/-1->1->0 [4] 2/-1/-1->1->0 [5] 2/-1/-1->1->0 [6] 2/-1/-1->1->0 [7] 2/-1/-1->1->0 [8] 2/-1/-1->1->0 [9] 2/-1/-1->1->0 [10] 2/-1/-1->1->0 [11] 2/-1/-1->1->0 [12] 2/-1/-1->1->0 [13] 2/-1/-1->1->0 [14] 2/-1/-1->1->0 [15] 2/-1/-1->1->0 [16] 2/-1/-1->1->0 [17] 2/-1/-1->1->0 [18] 2/-1/-1->1->0 [19] 2/-1/-1->1->0 [20] 2/-1/-1->1->0 [21] 2/-1/-1->1->0 [22] 2/-1/-1->1->0 [23] 2/-1/-1->1->0
run-mlperf--1-8m9qp:61:1109 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] 1/-1/-1->0->-1 [2] 1/-1/-1->0->-1 [3] 1/-1/-1->0->-1 [4] 1/-1/-1->0->-1 [5] 1/-1/-1->0->-1 [6] 1/-1/-1->0->-1 [7] 1/-1/-1->0->-1 [8] 1/-1/-1->0->-1 [9] 1/-1/-1->0->-1 [10] 1/-1/-1->0->-1 [11] 1/-1/-1->0->-1 [12] 1/-1/-1->0->-1 [13] 1/-1/-1->0->-1 [14] 1/-1/-1->0->-1 [15] 1/-1/-1->0->-1 [16] 1/-1/-1->0->-1 [17] 1/-1/-1->0->-1 [18] 1/-1/-1->0->-1 [19] 1/-1/-1->0->-1 [20] 1/-1/-1->0->-1 [21] 1/-1/-1->0->-1 [22] 1/-1/-1->0->-1 [23] 1/-1/-1->0->-1
run-mlperf--1-8m9qp:62:1114 [1] NCCL INFO Setting affinity for GPU 1 to f0000000,00000000
run-mlperf--1-8m9qp:61:1109 [0] NCCL INFO Setting affinity for GPU 0 to 0fff0000,00000000
run-mlperf--1-8m9qp:61:1109 [0] NCCL INFO Channel 00 : 0[7000] -> 1[f000] via P2P/IPC/read
run-mlperf--1-8m9qp:63:1117 [2] NCCL INFO Channel 00 : 2[47000] -> 3[4e000] via P2P/IPC/read
run-mlperf--1-8m9qp:62:1114 [1] NCCL INFO Channel 00 : 1[f000] -> 2[47000] via P2P/IPC/read
run-mlperf--1-8m9qp:64:1118 [3] NCCL INFO Channel 00 : 3[4e000] -> 0[7000] via P2P/IPC/read
run-mlperf--1-8m9qp:61:1109 [0] NCCL INFO Channel 01 : 0[7000] -> 1[f000] via P2P/IPC/read
run-mlperf--1-8m9qp:63:1117 [2] NCCL INFO Channel 01 : 2[47000] -> 3[4e000] via P2P/IPC/read
run-mlperf--1-8m9qp:62:1114 [1] NCCL INFO Channel 01 : 1[f000] -> 2[47000] via P2P/IPC/read
run-mlperf--1-8m9qp:64:1118 [3] NCCL INFO Channel 01 : 3[4e000] -> 0[7000] via P2P/IPC/read
run-mlperf--1-8m9qp:61:1109 [0] NCCL INFO Channel 02 : 0[7000] -> 1[f000] via P2P/IPC/read
run-mlperf--1-8m9qp:63:1117 [2] NCCL INFO Channel 02 : 2[47000] -> 3[4e000] via P2P/IPC/read
run-mlperf--1-8m9qp:62:1114 [1] NCCL INFO Channel 02 : 1[f000] -> 2[47000] via P2P/IPC/read
run-mlperf--1-8m9qp:64:1118 [3] NCCL INFO Channel 02 : 3[4e000] -> 0[7000] via P2P/IPC/read
run-mlperf--1-8m9qp:61:1109 [0] NCCL INFO Channel 03 : 0[7000] -> 1[f000] via P2P/IPC/read
run-mlperf--1-8m9qp:63:1117 [2] NCCL INFO Channel 03 : 2[47000] -> 3[4e000] via P2P/IPC/read
run-mlperf--1-8m9qp:62:1114 [1] NCCL INFO Channel 03 : 1[f000] -> 2[47000] via P2P/IPC/read
run-mlperf--1-8m9qp:64:1118 [3] NCCL INFO Channel 03 : 3[4e000] -> 0[7000] via P2P/IPC/read
run-mlperf--1-8m9qp:61:1109 [0] NCCL INFO Channel 04 : 0[7000] -> 1[f000] via P2P/IPC/read
run-mlperf--1-8m9qp:63:1117 [2] NCCL INFO Channel 04 : 2[47000] -> 3[4e000] via P2P/IPC/read
run-mlperf--1-8m9qp:62:1114 [1] NCCL INFO Channel 04 : 1[f000] -> 2[47000] via P2P/IPC/read
run-mlperf--1-8m9qp:64:1118 [3] NCCL INFO Channel 04 : 3[4e000] -> 0[7000] via P2P/IPC/read
run-mlperf--1-8m9qp:61:1109 [0] NCCL INFO Channel 05 : 0[7000] -> 1[f000] via P2P/IPC/read
run-mlperf--1-8m9qp:63:1117 [2] NCCL INFO Channel 05 : 2[47000] -> 3[4e000] via P2P/IPC/read
run-mlperf--1-8m9qp:62:1114 [1] NCCL INFO Channel 05 : 1[f000] -> 2[47000] via P2P/IPC/read
run-mlperf--1-8m9qp:64:1118 [3] NCCL INFO Channel 05 : 3[4e000] -> 0[7000] via P2P/IPC/read
run-mlperf--1-8m9qp:61:1109 [0] NCCL INFO Channel 06 : 0[7000] -> 1[f000] via P2P/IPC/read
run-mlperf--1-8m9qp:63:1117 [2] NCCL INFO Channel 06 : 2[47000] -> 3[4e000] via P2P/IPC/read
run-mlperf--1-8m9qp:62:1114 [1] NCCL INFO Channel 06 : 1[f000] -> 2[47000] via P2P/IPC/read
run-mlperf--1-8m9qp:64:1118 [3] NCCL INFO Channel 06 : 3[4e000] -> 0[7000] via P2P/IPC/read
run-mlperf--1-8m9qp:61:1109 [0] NCCL INFO Channel 07 : 0[7000] -> 1[f000] via P2P/IPC/read
run-mlperf--1-8m9qp:63:1117 [2] NCCL INFO Channel 07 : 2[47000] -> 3[4e000] via P2P/IPC/read
run-mlperf--1-8m9qp:62:1114 [1] NCCL INFO Channel 07 : 1[f000] -> 2[47000] via P2P/IPC/read
run-mlperf--1-8m9qp:64:1118 [3] NCCL INFO Channel 07 : 3[4e000] -> 0[7000] via P2P/IPC/read
run-mlperf--1-8m9qp:61:1109 [0] NCCL INFO Channel 08 : 0[7000] -> 1[f000] via P2P/IPC/read
run-mlperf--1-8m9qp:63:1117 [2] NCCL INFO Channel 08 : 2[47000] -> 3[4e000] via P2P/IPC/read
run-mlperf--1-8m9qp:62:1114 [1] NCCL INFO Channel 08 : 1[f000] -> 2[47000] via P2P/IPC/read
run-mlperf--1-8m9qp:64:1118 [3] NCCL INFO Channel 08 : 3[4e000] -> 0[7000] via P2P/IPC/read
run-mlperf--1-8m9qp:61:1109 [0] NCCL INFO Channel 09 : 0[7000] -> 1[f000] via P2P/IPC/read
run-mlperf--1-8m9qp:63:1117 [2] NCCL INFO Channel 09 : 2[47000] -> 3[4e000] via P2P/IPC/read
run-mlperf--1-8m9qp:62:1114 [1] NCCL INFO Channel 09 : 1[f000] -> 2[47000] via P2P/IPC/read
run-mlperf--1-8m9qp:64:1118 [3] NCCL INFO Channel 09 : 3[4e000] -> 0[7000] via P2P/IPC/read
run-mlperf--1-8m9qp:61:1109 [0] NCCL INFO Channel 10 : 0[7000] -> 1[f000] via P2P/IPC/read
run-mlperf--1-8m9qp:63:1117 [2] NCCL INFO Channel 10 : 2[47000] -> 3[4e000] via P2P/IPC/read
run-mlperf--1-8m9qp:62:1114 [1] NCCL INFO Channel 10 : 1[f000] -> 2[47000] via P2P/IPC/read
run-mlperf--1-8m9qp:64:1118 [3] NCCL INFO Channel 10 : 3[4e000] -> 0[7000] via P2P/IPC/read
run-mlperf--1-8m9qp:61:1109 [0] NCCL INFO Channel 11 : 0[7000] -> 1[f000] via P2P/IPC/read
run-mlperf--1-8m9qp:63:1117 [2] NCCL INFO Channel 11 : 2[47000] -> 3[4e000] via P2P/IPC/read
run-mlperf--1-8m9qp:62:1114 [1] NCCL INFO Channel 11 : 1[f000] -> 2[47000] via P2P/IPC/read
run-mlperf--1-8m9qp:64:1118 [3] NCCL INFO Channel 11 : 3[4e000] -> 0[7000] via P2P/IPC/read
run-mlperf--1-8m9qp:61:1109 [0] NCCL INFO Channel 12 : 0[7000] -> 1[f000] via P2P/IPC/read
run-mlperf--1-8m9qp:63:1117 [2] NCCL INFO Channel 12 : 2[47000] -> 3[4e000] via P2P/IPC/read
run-mlperf--1-8m9qp:62:1114 [1] NCCL INFO Channel 12 : 1[f000] -> 2[47000] via P2P/IPC/read
run-mlperf--1-8m9qp:64:1118 [3] NCCL INFO Channel 12 : 3[4e000] -> 0[7000] via P2P/IPC/read
run-mlperf--1-8m9qp:61:1109 [0] NCCL INFO Channel 13 : 0[7000] -> 1[f000] via P2P/IPC/read
run-mlperf--1-8m9qp:63:1117 [2] NCCL INFO Channel 13 : 2[47000] -> 3[4e000] via P2P/IPC/read
run-mlperf--1-8m9qp:62:1114 [1] NCCL INFO Channel 13 : 1[f000] -> 2[47000] via P2P/IPC/read
run-mlperf--1-8m9qp:64:1118 [3] NCCL INFO Channel 13 : 3[4e000] -> 0[7000] via P2P/IPC/read
run-mlperf--1-8m9qp:61:1109 [0] NCCL INFO Channel 14 : 0[7000] -> 1[f000] via P2P/IPC/read
run-mlperf--1-8m9qp:63:1117 [2] NCCL INFO Channel 14 : 2[47000] -> 3[4e000] via P2P/IPC/read
run-mlperf--1-8m9qp:62:1114 [1] NCCL INFO Channel 14 : 1[f000] -> 2[47000] via P2P/IPC/read
run-mlperf--1-8m9qp:64:1118 [3] NCCL INFO Channel 14 : 3[4e000] -> 0[7000] via P2P/IPC/read
run-mlperf--1-8m9qp:61:1109 [0] NCCL INFO Channel 15 : 0[7000] -> 1[f000] via P2P/IPC/read
run-mlperf--1-8m9qp:63:1117 [2] NCCL INFO Channel 15 : 2[47000] -> 3[4e000] via P2P/IPC/read
run-mlperf--1-8m9qp:62:1114 [1] NCCL INFO Channel 15 : 1[f000] -> 2[47000] via P2P/IPC/read
run-mlperf--1-8m9qp:64:1118 [3] NCCL INFO Channel 15 : 3[4e000] -> 0[7000] via P2P/IPC/read
run-mlperf--1-8m9qp:61:1109 [0] NCCL INFO Channel 16 : 0[7000] -> 1[f000] via P2P/IPC/read
run-mlperf--1-8m9qp:63:1117 [2] NCCL INFO Channel 16 : 2[47000] -> 3[4e000] via P2P/IPC/read
run-mlperf--1-8m9qp:62:1114 [1] NCCL INFO Channel 16 : 1[f000] -> 2[47000] via P2P/IPC/read
run-mlperf--1-8m9qp:64:1118 [3] NCCL INFO Channel 16 : 3[4e000] -> 0[7000] via P2P/IPC/read
run-mlperf--1-8m9qp:61:1109 [0] NCCL INFO Channel 17 : 0[7000] -> 1[f000] via P2P/IPC/read
run-mlperf--1-8m9qp:63:1117 [2] NCCL INFO Channel 17 : 2[47000] -> 3[4e000] via P2P/IPC/read
run-mlperf--1-8m9qp:62:1114 [1] NCCL INFO Channel 17 : 1[f000] -> 2[47000] via P2P/IPC/read
run-mlperf--1-8m9qp:64:1118 [3] NCCL INFO Channel 17 : 3[4e000] -> 0[7000] via P2P/IPC/read
run-mlperf--1-8m9qp:61:1109 [0] NCCL INFO Channel 18 : 0[7000] -> 1[f000] via P2P/IPC/read
run-mlperf--1-8m9qp:63:1117 [2] NCCL INFO Channel 18 : 2[47000] -> 3[4e000] via P2P/IPC/read
run-mlperf--1-8m9qp:62:1114 [1] NCCL INFO Channel 18 : 1[f000] -> 2[47000] via P2P/IPC/read
run-mlperf--1-8m9qp:64:1118 [3] NCCL INFO Channel 18 : 3[4e000] -> 0[7000] via P2P/IPC/read
run-mlperf--1-8m9qp:61:1109 [0] NCCL INFO Channel 19 : 0[7000] -> 1[f000] via P2P/IPC/read
run-mlperf--1-8m9qp:63:1117 [2] NCCL INFO Channel 19 : 2[47000] -> 3[4e000] via P2P/IPC/read
run-mlperf--1-8m9qp:62:1114 [1] NCCL INFO Channel 19 : 1[f000] -> 2[47000] via P2P/IPC/read
run-mlperf--1-8m9qp:64:1118 [3] NCCL INFO Channel 19 : 3[4e000] -> 0[7000] via P2P/IPC/read
run-mlperf--1-8m9qp:61:1109 [0] NCCL INFO Channel 20 : 0[7000] -> 1[f000] via P2P/IPC/read
run-mlperf--1-8m9qp:63:1117 [2] NCCL INFO Channel 20 : 2[47000] -> 3[4e000] via P2P/IPC/read
run-mlperf--1-8m9qp:62:1114 [1] NCCL INFO Channel 20 : 1[f000] -> 2[47000] via P2P/IPC/read
run-mlperf--1-8m9qp:64:1118 [3] NCCL INFO Channel 20 : 3[4e000] -> 0[7000] via P2P/IPC/read
run-mlperf--1-8m9qp:61:1109 [0] NCCL INFO Channel 21 : 0[7000] -> 1[f000] via P2P/IPC/read
run-mlperf--1-8m9qp:63:1117 [2] NCCL INFO Channel 21 : 2[47000] -> 3[4e000] via P2P/IPC/read
run-mlperf--1-8m9qp:62:1114 [1] NCCL INFO Channel 21 : 1[f000] -> 2[47000] via P2P/IPC/read
run-mlperf--1-8m9qp:64:1118 [3] NCCL INFO Channel 21 : 3[4e000] -> 0[7000] via P2P/IPC/read
run-mlperf--1-8m9qp:61:1109 [0] NCCL INFO Channel 22 : 0[7000] -> 1[f000] via P2P/IPC/read
run-mlperf--1-8m9qp:63:1117 [2] NCCL INFO Channel 22 : 2[47000] -> 3[4e000] via P2P/IPC/read
run-mlperf--1-8m9qp:62:1114 [1] NCCL INFO Channel 22 : 1[f000] -> 2[47000] via P2P/IPC/read
run-mlperf--1-8m9qp:64:1118 [3] NCCL INFO Channel 22 : 3[4e000] -> 0[7000] via P2P/IPC/read
run-mlperf--1-8m9qp:61:1109 [0] NCCL INFO Channel 23 : 0[7000] -> 1[f000] via P2P/IPC/read
run-mlperf--1-8m9qp:63:1117 [2] NCCL INFO Channel 23 : 2[47000] -> 3[4e000] via P2P/IPC/read
run-mlperf--1-8m9qp:62:1114 [1] NCCL INFO Channel 23 : 1[f000] -> 2[47000] via P2P/IPC/read
run-mlperf--1-8m9qp:64:1118 [3] NCCL INFO Channel 23 : 3[4e000] -> 0[7000] via P2P/IPC/read
run-mlperf--1-8m9qp:62:1114 [1] NCCL INFO Connected all rings
run-mlperf--1-8m9qp:63:1117 [2] NCCL INFO Connected all rings
run-mlperf--1-8m9qp:61:1109 [0] NCCL INFO Connected all rings
run-mlperf--1-8m9qp:64:1118 [3] NCCL INFO Connected all rings
run-mlperf--1-8m9qp:64:1118 [3] NCCL INFO Channel 00 : 3[4e000] -> 2[47000] via P2P/IPC/read
run-mlperf--1-8m9qp:64:1118 [3] NCCL INFO Channel 01 : 3[4e000] -> 2[47000] via P2P/IPC/read
run-mlperf--1-8m9qp:64:1118 [3] NCCL INFO Channel 02 : 3[4e000] -> 2[47000] via P2P/IPC/read
run-mlperf--1-8m9qp:64:1118 [3] NCCL INFO Channel 03 : 3[4e000] -> 2[47000] via P2P/IPC/read
run-mlperf--1-8m9qp:64:1118 [3] NCCL INFO Channel 04 : 3[4e000] -> 2[47000] via P2P/IPC/read
run-mlperf--1-8m9qp:64:1118 [3] NCCL INFO Channel 05 : 3[4e000] -> 2[47000] via P2P/IPC/read
run-mlperf--1-8m9qp:64:1118 [3] NCCL INFO Channel 06 : 3[4e000] -> 2[47000] via P2P/IPC/read
run-mlperf--1-8m9qp:64:1118 [3] NCCL INFO Channel 07 : 3[4e000] -> 2[47000] via P2P/IPC/read
run-mlperf--1-8m9qp:64:1118 [3] NCCL INFO Channel 08 : 3[4e000] -> 2[47000] via P2P/IPC/read
run-mlperf--1-8m9qp:64:1118 [3] NCCL INFO Channel 09 : 3[4e000] -> 2[47000] via P2P/IPC/read
run-mlperf--1-8m9qp:64:1118 [3] NCCL INFO Channel 10 : 3[4e000] -> 2[47000] via P2P/IPC/read
run-mlperf--1-8m9qp:64:1118 [3] NCCL INFO Channel 11 : 3[4e000] -> 2[47000] via P2P/IPC/read
run-mlperf--1-8m9qp:64:1118 [3] NCCL INFO Channel 12 : 3[4e000] -> 2[47000] via P2P/IPC/read
run-mlperf--1-8m9qp:64:1118 [3] NCCL INFO Channel 13 : 3[4e000] -> 2[47000] via P2P/IPC/read
run-mlperf--1-8m9qp:64:1118 [3] NCCL INFO Channel 14 : 3[4e000] -> 2[47000] via P2P/IPC/read
run-mlperf--1-8m9qp:64:1118 [3] NCCL INFO Channel 15 : 3[4e000] -> 2[47000] via P2P/IPC/read
run-mlperf--1-8m9qp:64:1118 [3] NCCL INFO Channel 16 : 3[4e000] -> 2[47000] via P2P/IPC/read
run-mlperf--1-8m9qp:64:1118 [3] NCCL INFO Channel 17 : 3[4e000] -> 2[47000] via P2P/IPC/read
run-mlperf--1-8m9qp:64:1118 [3] NCCL INFO Channel 18 : 3[4e000] -> 2[47000] via P2P/IPC/read
run-mlperf--1-8m9qp:64:1118 [3] NCCL INFO Channel 19 : 3[4e000] -> 2[47000] via P2P/IPC/read
run-mlperf--1-8m9qp:64:1118 [3] NCCL INFO Channel 20 : 3[4e000] -> 2[47000] via P2P/IPC/read
run-mlperf--1-8m9qp:64:1118 [3] NCCL INFO Channel 21 : 3[4e000] -> 2[47000] via P2P/IPC/read
run-mlperf--1-8m9qp:64:1118 [3] NCCL INFO Channel 22 : 3[4e000] -> 2[47000] via P2P/IPC/read
run-mlperf--1-8m9qp:64:1118 [3] NCCL INFO Channel 23 : 3[4e000] -> 2[47000] via P2P/IPC/read
run-mlperf--1-8m9qp:62:1114 [1] NCCL INFO Channel 00 : 1[f000] -> 0[7000] via P2P/IPC/read
run-mlperf--1-8m9qp:63:1117 [2] NCCL INFO Channel 00 : 2[47000] -> 1[f000] via P2P/IPC/read
run-mlperf--1-8m9qp:62:1114 [1] NCCL INFO Channel 01 : 1[f000] -> 0[7000] via P2P/IPC/read
run-mlperf--1-8m9qp:63:1117 [2] NCCL INFO Channel 01 : 2[47000] -> 1[f000] via P2P/IPC/read
run-mlperf--1-8m9qp:62:1114 [1] NCCL INFO Channel 02 : 1[f000] -> 0[7000] via P2P/IPC/read
run-mlperf--1-8m9qp:63:1117 [2] NCCL INFO Channel 02 : 2[47000] -> 1[f000] via P2P/IPC/read
run-mlperf--1-8m9qp:62:1114 [1] NCCL INFO Channel 03 : 1[f000] -> 0[7000] via P2P/IPC/read
run-mlperf--1-8m9qp:63:1117 [2] NCCL INFO Channel 03 : 2[47000] -> 1[f000] via P2P/IPC/read
run-mlperf--1-8m9qp:62:1114 [1] NCCL INFO Channel 04 : 1[f000] -> 0[7000] via P2P/IPC/read
run-mlperf--1-8m9qp:63:1117 [2] NCCL INFO Channel 04 : 2[47000] -> 1[f000] via P2P/IPC/read
run-mlperf--1-8m9qp:62:1114 [1] NCCL INFO Channel 05 : 1[f000] -> 0[7000] via P2P/IPC/read
run-mlperf--1-8m9qp:63:1117 [2] NCCL INFO Channel 05 : 2[47000] -> 1[f000] via P2P/IPC/read
run-mlperf--1-8m9qp:62:1114 [1] NCCL INFO Channel 06 : 1[f000] -> 0[7000] via P2P/IPC/read
run-mlperf--1-8m9qp:63:1117 [2] NCCL INFO Channel 06 : 2[47000] -> 1[f000] via P2P/IPC/read
run-mlperf--1-8m9qp:62:1114 [1] NCCL INFO Channel 07 : 1[f000] -> 0[7000] via P2P/IPC/read
run-mlperf--1-8m9qp:63:1117 [2] NCCL INFO Channel 07 : 2[47000] -> 1[f000] via P2P/IPC/read
run-mlperf--1-8m9qp:62:1114 [1] NCCL INFO Channel 08 : 1[f000] -> 0[7000] via P2P/IPC/read
run-mlperf--1-8m9qp:63:1117 [2] NCCL INFO Channel 08 : 2[47000] -> 1[f000] via P2P/IPC/read
run-mlperf--1-8m9qp:62:1114 [1] NCCL INFO Channel 09 : 1[f000] -> 0[7000] via P2P/IPC/read
run-mlperf--1-8m9qp:63:1117 [2] NCCL INFO Channel 09 : 2[47000] -> 1[f000] via P2P/IPC/read
run-mlperf--1-8m9qp:62:1114 [1] NCCL INFO Channel 10 : 1[f000] -> 0[7000] via P2P/IPC/read
run-mlperf--1-8m9qp:63:1117 [2] NCCL INFO Channel 10 : 2[47000] -> 1[f000] via P2P/IPC/read
run-mlperf--1-8m9qp:62:1114 [1] NCCL INFO Channel 11 : 1[f000] -> 0[7000] via P2P/IPC/read
run-mlperf--1-8m9qp:63:1117 [2] NCCL INFO Channel 11 : 2[47000] -> 1[f000] via P2P/IPC/read
run-mlperf--1-8m9qp:62:1114 [1] NCCL INFO Channel 12 : 1[f000] -> 0[7000] via P2P/IPC/read
run-mlperf--1-8m9qp:63:1117 [2] NCCL INFO Channel 12 : 2[47000] -> 1[f000] via P2P/IPC/read
run-mlperf--1-8m9qp:62:1114 [1] NCCL INFO Channel 13 : 1[f000] -> 0[7000] via P2P/IPC/read
run-mlperf--1-8m9qp:63:1117 [2] NCCL INFO Channel 13 : 2[47000] -> 1[f000] via P2P/IPC/read
run-mlperf--1-8m9qp:62:1114 [1] NCCL INFO Channel 14 : 1[f000] -> 0[7000] via P2P/IPC/read
run-mlperf--1-8m9qp:63:1117 [2] NCCL INFO Channel 14 : 2[47000] -> 1[f000] via P2P/IPC/read
run-mlperf--1-8m9qp:62:1114 [1] NCCL INFO Channel 15 : 1[f000] -> 0[7000] via P2P/IPC/read
run-mlperf--1-8m9qp:63:1117 [2] NCCL INFO Channel 15 : 2[47000] -> 1[f000] via P2P/IPC/read
run-mlperf--1-8m9qp:62:1114 [1] NCCL INFO Channel 16 : 1[f000] -> 0[7000] via P2P/IPC/read
run-mlperf--1-8m9qp:63:1117 [2] NCCL INFO Channel 16 : 2[47000] -> 1[f000] via P2P/IPC/read
run-mlperf--1-8m9qp:62:1114 [1] NCCL INFO Channel 17 : 1[f000] -> 0[7000] via P2P/IPC/read
run-mlperf--1-8m9qp:63:1117 [2] NCCL INFO Channel 17 : 2[47000] -> 1[f000] via P2P/IPC/read
run-mlperf--1-8m9qp:62:1114 [1] NCCL INFO Channel 18 : 1[f000] -> 0[7000] via P2P/IPC/read
run-mlperf--1-8m9qp:63:1117 [2] NCCL INFO Channel 18 : 2[47000] -> 1[f000] via P2P/IPC/read
run-mlperf--1-8m9qp:62:1114 [1] NCCL INFO Channel 19 : 1[f000] -> 0[7000] via P2P/IPC/read
run-mlperf--1-8m9qp:63:1117 [2] NCCL INFO Channel 19 : 2[47000] -> 1[f000] via P2P/IPC/read
run-mlperf--1-8m9qp:62:1114 [1] NCCL INFO Channel 20 : 1[f000] -> 0[7000] via P2P/IPC/read
run-mlperf--1-8m9qp:63:1117 [2] NCCL INFO Channel 20 : 2[47000] -> 1[f000] via P2P/IPC/read
run-mlperf--1-8m9qp:62:1114 [1] NCCL INFO Channel 21 : 1[f000] -> 0[7000] via P2P/IPC/read
run-mlperf--1-8m9qp:63:1117 [2] NCCL INFO Channel 21 : 2[47000] -> 1[f000] via P2P/IPC/read
run-mlperf--1-8m9qp:62:1114 [1] NCCL INFO Channel 22 : 1[f000] -> 0[7000] via P2P/IPC/read
run-mlperf--1-8m9qp:63:1117 [2] NCCL INFO Channel 22 : 2[47000] -> 1[f000] via P2P/IPC/read
run-mlperf--1-8m9qp:62:1114 [1] NCCL INFO Channel 23 : 1[f000] -> 0[7000] via P2P/IPC/read
run-mlperf--1-8m9qp:63:1117 [2] NCCL INFO Channel 23 : 2[47000] -> 1[f000] via P2P/IPC/read
run-mlperf--1-8m9qp:61:1109 [0] NCCL INFO Connected all trees
run-mlperf--1-8m9qp:61:1109 [0] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 8/8/512
run-mlperf--1-8m9qp:64:1118 [3] NCCL INFO Connected all trees
run-mlperf--1-8m9qp:64:1118 [3] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 8/8/512
run-mlperf--1-8m9qp:61:1109 [0] NCCL INFO 24 coll channels, 32 p2p channels, 32 p2p channels per peer
run-mlperf--1-8m9qp:64:1118 [3] NCCL INFO 24 coll channels, 32 p2p channels, 32 p2p channels per peer
run-mlperf--1-8m9qp:62:1114 [1] NCCL INFO Connected all trees
run-mlperf--1-8m9qp:62:1114 [1] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 8/8/512
run-mlperf--1-8m9qp:63:1117 [2] NCCL INFO Connected all trees
run-mlperf--1-8m9qp:63:1117 [2] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 8/8/512
run-mlperf--1-8m9qp:62:1114 [1] NCCL INFO 24 coll channels, 32 p2p channels, 32 p2p channels per peer
run-mlperf--1-8m9qp:63:1117 [2] NCCL INFO 24 coll channels, 32 p2p channels, 32 p2p channels per peer
run-mlperf--1-8m9qp:62:1114 [1] NCCL INFO comm 0x7f3b7c008fb0 rank 1 nranks 4 cudaDev 1 busId f000 - Init COMPLETE
run-mlperf--1-8m9qp:64:1118 [3] NCCL INFO comm 0x7f368c008fb0 rank 3 nranks 4 cudaDev 3 busId 4e000 - Init COMPLETE
run-mlperf--1-8m9qp:63:1117 [2] NCCL INFO comm 0x7fbe10008fb0 rank 2 nranks 4 cudaDev 2 busId 47000 - Init COMPLETE
run-mlperf--1-8m9qp:61:1109 [0] NCCL INFO comm 0x7f9484008fb0 rank 0 nranks 4 cudaDev 0 busId 7000 - Init COMPLETE
run-mlperf--1-8m9qp:61:61 [0] NCCL INFO Launch mode Parallel
:::MLLOG {"namespace": "", "time_ms": 1639608888121, "event_type": "POINT_IN_TIME", "key": "seed", "value": 950755392, "metadata": {"file": "tools/train_mlperf.py", "lineno": 469}}
2021-12-15 22:54:48,127 maskrcnn_benchmark INFO: Using 4 GPUs
2021-12-15 22:54:48,128 maskrcnn_benchmark INFO: Namespace(config_file='configs/e2e_mask_rcnn_R_50_FPN_1x.yaml', distributed=True, local_rank=0, opts=['DTYPE', 'float16', 'PATHS_CATALOG', 'maskrcnn_benchmark/config/paths_catalog_dbcluster.py', 'MODEL.WEIGHT', '/data/coco2017/models/R-50.pkl', 'DISABLE_REDUCED_LOGGING', 'True', 'SOLVER.BASE_LR', '0.12', 'SOLVER.WARMUP_FACTOR', '0.000192', 'SOLVER.WARMUP_ITERS', '625', 'SOLVER.WARMUP_METHOD', 'mlperf_linear', 'SOLVER.STEPS', '(12000,16000)', 'SOLVER.IMS_PER_BATCH', '96', 'TEST.IMS_PER_BATCH', '96', 'MODEL.RPN.FPN_POST_NMS_TOP_N_TRAIN', '12000', 'MODEL.RPN.FPN_POST_NMS_TOP_N_PER_IMAGE', 'False', 'NHWC', 'True', 'MODEL.RESNETS.FIRST_TRANS_FUNC', 'FastBottleneckWithFixedBatchNorm', 'MODEL.RESNETS.TRANS_FUNC', 'FastBottleneckWithFixedBatchNorm', 'SOLVER.MAX_ITER', '40000', 'DATALOADER.DALI', 'False', 'DATALOADER.DALI_ON_GPU', 'False', 'DATALOADER.CACHE_EVAL_IMAGES', 'True', 'EVAL_SEGM_NUMPROCS', '10', 'USE_CUDA_GRAPH', 'True', 'EVAL_MASK_VIRTUAL_PASTE', 'True', 'MODEL.BACKBONE.INCLUDE_RPN_HEAD', 'True', 'DATALOADER.NUM_WORKERS', '1', 'PRECOMPUTE_RPN_CONSTANT_TENSORS', 'True', 'DATALOADER.HYBRID', 'True'], seed=950755392)
2021-12-15 22:54:48,128 maskrcnn_benchmark INFO: Worker 0: Setting seed 3633440948
2021-12-15 22:54:48,128 maskrcnn_benchmark INFO: Collecting env info (might take some time)

run-mlperf--1-8m9qp:62:1110 [0] p2p_plugin.c:141 NCCL WARN NET/IB : Got async event : GID table change

run-mlperf--1-8m9qp:64:1112 [0] p2p_plugin.c:141 NCCL WARN NET/IB : Got async event : GID table change

run-mlperf--1-8m9qp:61:1106 [0] p2p_plugin.c:141 NCCL WARN NET/IB : Got async event : GID table change

run-mlperf--1-8m9qp:63:1111 [0] p2p_plugin.c:141 NCCL WARN NET/IB : Got async event : GID table change

run-mlperf--1-8m9qp:61:1106 [0] p2p_plugin.c:141 NCCL WARN NET/IB : Got async event : GID table change

run-mlperf--1-8m9qp:62:1110 [0] p2p_plugin.c:141 NCCL WARN NET/IB : Got async event : GID table change

run-mlperf--1-8m9qp:64:1112 [0] p2p_plugin.c:141 NCCL WARN NET/IB : Got async event : GID table change

run-mlperf--1-8m9qp:63:1111 [0] p2p_plugin.c:141 NCCL WARN NET/IB : Got async event : GID table change

run-mlperf--1-8m9qp:61:1106 [0] p2p_plugin.c:141 NCCL WARN NET/IB : Got async event : GID table change

run-mlperf--1-8m9qp:64:1112 [0] p2p_plugin.c:141 NCCL WARN NET/IB : Got async event : GID table change

run-mlperf--1-8m9qp:62:1110 [0] p2p_plugin.c:141 NCCL WARN NET/IB : Got async event : GID table change

run-mlperf--1-8m9qp:63:1111 [0] p2p_plugin.c:141 NCCL WARN NET/IB : Got async event : GID table change

run-mlperf--1-8m9qp:61:1106 [0] p2p_plugin.c:141 NCCL WARN NET/IB : Got async event : GID table change

run-mlperf--1-8m9qp:63:1111 [0] p2p_plugin.c:141 NCCL WARN NET/IB : Got async event : GID table change

run-mlperf--1-8m9qp:62:1110 [0] p2p_plugin.c:141 NCCL WARN NET/IB : Got async event : GID table change

run-mlperf--1-8m9qp:64:1112 [0] p2p_plugin.c:141 NCCL WARN NET/IB : Got async event : GID table change
/opt/conda/lib/python3.8/site-packages/torch/nn/modules/conv.py:1092: UserWarning: _ConvTransposeMixin is a deprecated internal class. Please consider using public APIs.
  warnings.warn(
[(800, 1344), (1344, 800)]
USE_CUDA_GRAPH :: per_gpu_batch_sizes = [(True, 24), (False, 24)]
2021-12-15 22:54:53,165 maskrcnn_benchmark INFO: 
PyTorch version: 1.10.0a0+3fd9dcf
Is debug build: False
CUDA used to build PyTorch: 11.4
ROCM used to build PyTorch: N/A

OS: Ubuntu 20.04.3 LTS (x86_64)
GCC version: (Ubuntu 9.3.0-17ubuntu1~20.04) 9.3.0
Clang version: Could not collect
CMake version: version 3.21.2
Libc version: glibc-2.31

Python version: 3.8.10 | packaged by conda-forge | (default, May 11 2021, 07:01:05)  [GCC 9.3.0] (64-bit runtime)
Python platform: Linux-4.18.0-305.19.1.el8_4.x86_64-x86_64-with-glibc2.10
Is CUDA available: True
CUDA runtime version: 11.4.120
GPU models and configuration: 
GPU 0: NVIDIA A100-SXM4-40GB
GPU 1: NVIDIA A100-SXM4-40GB
GPU 2: NVIDIA A100-SXM4-40GB
GPU 3: NVIDIA A100-SXM4-40GB

Nvidia driver version: 470.82.01
cuDNN version: Probably one of the following:
/usr/lib/x86_64-linux-gnu/libcudnn.so.8.2.4
/usr/lib/x86_64-linux-gnu/libcudnn_adv_infer.so.8.2.4
/usr/lib/x86_64-linux-gnu/libcudnn_adv_train.so.8.2.4
/usr/lib/x86_64-linux-gnu/libcudnn_cnn_infer.so.8.2.4
/usr/lib/x86_64-linux-gnu/libcudnn_cnn_train.so.8.2.4
/usr/lib/x86_64-linux-gnu/libcudnn_ops_infer.so.8.2.4
/usr/lib/x86_64-linux-gnu/libcudnn_ops_train.so.8.2.4
HIP runtime version: N/A
MIOpen runtime version: N/A

Versions of relevant libraries:
[pip3] numpy==1.21.2
[pip3] nvidia-dlprof-pytorch-nvtx==1.5.0
[pip3] pytorch-quantization==2.1.0
[pip3] torch==1.10.0a0+3fd9dcf
[pip3] torchtext==0.11.0a0
[pip3] torchvision==0.11.0a0
[conda] magma-cuda110             2.5.2                         5    local
[conda] mkl                       2019.5                      281    conda-forge
[conda] mkl-include               2019.5                      281    conda-forge
[conda] numpy                     1.21.2           py38he2449b9_0    conda-forge
[conda] nvidia-dlprof-pytorch-nvtx 1.5.0                    pypi_0    pypi
[conda] pytorch-quantization      2.1.0                    pypi_0    pypi
[conda] torch                     1.10.0a0+3fd9dcf          pypi_0    pypi
[conda] torchtext                 0.11.0a0                 pypi_0    pypi
[conda] torchvision               0.11.0a0                 pypi_0    pypi
        Pillow (8.2.0)
2021-12-15 22:54:53,166 maskrcnn_benchmark INFO: Loaded configuration file configs/e2e_mask_rcnn_R_50_FPN_1x.yaml
2021-12-15 22:54:53,166 maskrcnn_benchmark INFO: 
MODEL:
  META_ARCHITECTURE: "GeneralizedRCNN"
  WEIGHT: "catalog://ImageNetPretrained/MSRA/R-50"
  BACKBONE:
    CONV_BODY: "R-50-FPN"
    OUT_CHANNELS: 256
  RPN:
    USE_FPN: True
    ANCHOR_STRIDE: (4, 8, 16, 32, 64)
    PRE_NMS_TOP_N_TRAIN: 2000
    PRE_NMS_TOP_N_TEST: 1000
    POST_NMS_TOP_N_TEST: 1000
    FPN_POST_NMS_TOP_N_TEST: 1000
  ROI_HEADS:
    USE_FPN: True
  ROI_BOX_HEAD:
    POOLER_RESOLUTION: 7
    POOLER_SCALES: (0.25, 0.125, 0.0625, 0.03125)
    POOLER_SAMPLING_RATIO: 2
    FEATURE_EXTRACTOR: "FPN2MLPFeatureExtractor"
    PREDICTOR: "FPNPredictor"
  ROI_MASK_HEAD:
    POOLER_SCALES: (0.25, 0.125, 0.0625, 0.03125)
    FEATURE_EXTRACTOR: "MaskRCNNFPNFeatureExtractor"
    PREDICTOR: "MaskRCNNC4Predictor"
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 2
    RESOLUTION: 28
    SHARE_BOX_FEATURE_EXTRACTOR: False
  MASK_ON: True
DATASETS:
  TRAIN: ("coco_2017_train",)
  TEST: ("coco_2017_val",)
DATALOADER:
  SIZE_DIVISIBILITY: 32
SOLVER:
  BASE_LR: 0.02
  WEIGHT_DECAY: 0.0001
  STEPS: (60000, 80000)
  MAX_ITER: 90000

2021-12-15 22:54:53,166 maskrcnn_benchmark INFO: Running with config:
AMP_VERBOSE: False
CUDA_GRAPH_NUM_SHAPES_PER_ORIENTATION: 1
DATALOADER:
  ALWAYS_PAD_TO_MAX: False
  ASPECT_RATIO_GROUPING: True
  CACHE_EVAL_IMAGES: True
  DALI: False
  DALI_ON_GPU: False
  HYBRID: True
  MAX_ANNOTATIONS_PER_IMAGE: 0
  NUM_WORKERS: 1
  SIZE_DIVISIBILITY: 32
DATASETS:
  TEST: ('coco_2017_val',)
  TRAIN: ('coco_2017_train',)
DISABLE_LOSS_LOGGING: False
DISABLE_REDUCED_LOGGING: True
DTYPE: float16
DYNAMIC_LOSS_SCALE_WINDOW: 1000
EVAL_MASK_VIRTUAL_PASTE: True
EVAL_SEGM_NUMPROCS: 10
FUSED_SGD_DEBUG_PRINTS: False
INPUT:
  MAX_SIZE_TEST: 1333
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 800
  MIN_SIZE_TRAIN: (800,)
  PIXEL_MEAN: [102.9801, 115.9465, 122.7717]
  PIXEL_STD: [1.0, 1.0, 1.0]
  TO_BGR255: True
MLPERF:
  MIN_BBOX_MAP: 0.377
  MIN_SEGM_MAP: 0.339
MODEL:
  BACKBONE:
    CONV_BODY: R-50-FPN
    FREEZE_CONV_BODY_AT: 2
    INCLUDE_RPN_HEAD: True
    OUT_CHANNELS: 256
    USE_GN: False
  CLS_AGNOSTIC_BBOX_REG: False
  DEVICE: cuda
  FPN:
    USE_GN: False
    USE_RELU: False
  GROUP_NORM:
    DIM_PER_GP: -1
    EPSILON: 1e-05
    NUM_GROUPS: 32
  KEYPOINT_ON: False
  MASK_ON: True
  META_ARCHITECTURE: GeneralizedRCNN
  RESNETS:
    FIRST_TRANS_FUNC: FastBottleneckWithFixedBatchNorm
    NUM_GROUPS: 1
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STEM_FUNC: StemWithFixedBatchNorm
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: True
    TRANS_FUNC: FastBottleneckWithFixedBatchNorm
    WIDTH_PER_GROUP: 64
  RETINANET:
    ANCHOR_SIZES: (32, 64, 128, 256, 512)
    ANCHOR_STRIDES: (8, 16, 32, 64, 128)
    ASPECT_RATIOS: (0.5, 1.0, 2.0)
    BBOX_REG_BETA: 0.11
    BBOX_REG_WEIGHT: 4.0
    BG_IOU_THRESHOLD: 0.4
    FG_IOU_THRESHOLD: 0.5
    INFERENCE_TH: 0.05
    LOSS_ALPHA: 0.25
    LOSS_GAMMA: 2.0
    NMS_TH: 0.4
    NUM_CLASSES: 81
    NUM_CONVS: 4
    OCTAVE: 2.0
    PRE_NMS_TOP_N: 1000
    PRIOR_PROB: 0.01
    SCALES_PER_OCTAVE: 3
    STRADDLE_THRESH: 0
    USE_C5: True
  RETINANET_ON: False
  ROI_BOX_HEAD:
    CONV_HEAD_DIM: 256
    DILATION: 1
    FEATURE_EXTRACTOR: FPN2MLPFeatureExtractor
    MLP_HEAD_DIM: 1024
    NUM_CLASSES: 81
    NUM_STACKED_CONVS: 4
    POOLER_RESOLUTION: 7
    POOLER_SAMPLING_RATIO: 2
    POOLER_SCALES: (0.25, 0.125, 0.0625, 0.03125)
    PREDICTOR: FPNPredictor
    USE_GN: False
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 512
    BBOX_REG_WEIGHTS: (10.0, 10.0, 5.0, 5.0)
    BG_IOU_THRESHOLD: 0.5
    DETECTIONS_PER_IMG: 100
    FG_IOU_THRESHOLD: 0.5
    NMS: 0.5
    POSITIVE_FRACTION: 0.25
    SCORE_THRESH: 0.05
    USE_FPN: True
  ROI_KEYPOINT_HEAD:
    CONV_LAYERS: (512, 512, 512, 512, 512, 512, 512, 512)
    FEATURE_EXTRACTOR: KeypointRCNNFeatureExtractor
    MLP_HEAD_DIM: 1024
    NUM_CLASSES: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_SCALES: (0.0625,)
    PREDICTOR: KeypointRCNNPredictor
    RESOLUTION: 14
    SHARE_BOX_FEATURE_EXTRACTOR: True
  ROI_MASK_HEAD:
    CONV_LAYERS: (256, 256, 256, 256)
    DILATION: 1
    FEATURE_EXTRACTOR: MaskRCNNFPNFeatureExtractor
    MLP_HEAD_DIM: 1024
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 2
    POOLER_SCALES: (0.25, 0.125, 0.0625, 0.03125)
    POSTPROCESS_MASKS: False
    POSTPROCESS_MASKS_THRESHOLD: 0.5
    PREDICTOR: MaskRCNNC4Predictor
    RESOLUTION: 28
    SHARE_BOX_FEATURE_EXTRACTOR: False
    USE_GN: False
  RPN:
    ANCHOR_SIZES: (32, 64, 128, 256, 512)
    ANCHOR_STRIDE: (4, 8, 16, 32, 64)
    ASPECT_RATIOS: (0.5, 1.0, 2.0)
    BATCH_SIZE_PER_IMAGE: 256
    BG_IOU_THRESHOLD: 0.3
    FG_IOU_THRESHOLD: 0.7
    FPN_POST_NMS_TOP_N_PER_IMAGE: False
    FPN_POST_NMS_TOP_N_TEST: 1000
    FPN_POST_NMS_TOP_N_TRAIN: 12000
    MIN_SIZE: 0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOP_N_TEST: 1000
    POST_NMS_TOP_N_TRAIN: 2000
    PRE_NMS_TOP_N_TEST: 1000
    PRE_NMS_TOP_N_TRAIN: 2000
    RPN_HEAD: SingleConvRPNHead
    STRADDLE_THRESH: 0
    USE_FPN: True
  RPN_ONLY: False
  WEIGHT: /data/coco2017/models/R-50.pkl
NHWC: True
OUTPUT_DIR: .
PATHS_CATALOG: maskrcnn_benchmark/config/paths_catalog_dbcluster.py
PER_EPOCH_EVAL: True
PRECOMPUTE_RPN_CONSTANT_TENSORS: True
SAVE_CHECKPOINTS: False
SOLVER:
  BASE_LR: 0.12
  BIAS_LR_FACTOR: 2
  CHECKPOINT_PERIOD: 2500
  GAMMA: 0.1
  IMS_PER_BATCH: 96
  MAX_ITER: 40000
  MOMENTUM: 0.9
  STEPS: (12000, 16000)
  WARMUP_FACTOR: 0.000192
  WARMUP_ITERS: 625
  WARMUP_METHOD: mlperf_linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: 0
SYNCFREE_ROI: True
TEST:
  DETECTIONS_PER_IMG: 100
  EXPECTED_RESULTS: []
  EXPECTED_RESULTS_SIGMA_TOL: 4
  IMS_PER_BATCH: 96
USE_CUDA_GRAPH: True
:::MLLOG {"namespace": "", "time_ms": 1639608893167, "event_type": "POINT_IN_TIME", "key": "d_batch_size", "value": 24.0, "metadata": {"file": "tools/train_mlperf.py", "lineno": 509}}
:::MLLOG {"namespace": "", "time_ms": 1639608893167, "event_type": "POINT_IN_TIME", "key": "global_batch_size", "value": 96, "metadata": {"file": "tools/train_mlperf.py", "lineno": 186}}
:::MLLOG {"namespace": "", "time_ms": 1639608893167, "event_type": "POINT_IN_TIME", "key": "num_image_candidates", "value": 12000, "metadata": {"file": "tools/train_mlperf.py", "lineno": 187}}
:::MLLOG {"namespace": "", "time_ms": 1639608893167, "event_type": "POINT_IN_TIME", "key": "gradient_accumulation_steps", "value": 1, "metadata": {"file": "tools/train_mlperf.py", "lineno": 188}}
:::MLLOG {"namespace": "", "time_ms": 1639608893517, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/object_detection/maskrcnn_benchmark/modeling/backbone/fpn.py", "lineno": 44, "tensor": "FPN_inner_block1"}}
:::MLLOG {"namespace": "", "time_ms": 1639608893524, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/object_detection/maskrcnn_benchmark/modeling/backbone/fpn.py", "lineno": 47, "tensor": "FPN_layer_block1"}}
:::MLLOG {"namespace": "", "time_ms": 1639608893526, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/object_detection/maskrcnn_benchmark/modeling/backbone/fpn.py", "lineno": 44, "tensor": "FPN_inner_block2"}}
:::MLLOG {"namespace": "", "time_ms": 1639608893533, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/object_detection/maskrcnn_benchmark/modeling/backbone/fpn.py", "lineno": 47, "tensor": "FPN_layer_block2"}}
:::MLLOG {"namespace": "", "time_ms": 1639608893536, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/object_detection/maskrcnn_benchmark/modeling/backbone/fpn.py", "lineno": 44, "tensor": "FPN_inner_block3"}}
:::MLLOG {"namespace": "", "time_ms": 1639608893544, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/object_detection/maskrcnn_benchmark/modeling/backbone/fpn.py", "lineno": 47, "tensor": "FPN_layer_block3"}}
:::MLLOG {"namespace": "", "time_ms": 1639608893549, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/object_detection/maskrcnn_benchmark/modeling/backbone/fpn.py", "lineno": 44, "tensor": "FPN_inner_block4"}}
:::MLLOG {"namespace": "", "time_ms": 1639608893556, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/object_detection/maskrcnn_benchmark/modeling/backbone/fpn.py", "lineno": 47, "tensor": "FPN_layer_block4"}}
:::MLLOG {"namespace": "", "time_ms": 1639608893564, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/object_detection/maskrcnn_benchmark/modeling/rpn/rpn.py", "lineno": 44, "tensor": "RPNHead_conv"}}
:::MLLOG {"namespace": "", "time_ms": 1639608893564, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/object_detection/maskrcnn_benchmark/modeling/rpn/rpn.py", "lineno": 45, "tensor": "RPNHead_cls"}}
:::MLLOG {"namespace": "", "time_ms": 1639608893564, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/object_detection/maskrcnn_benchmark/modeling/rpn/rpn.py", "lineno": 46, "tensor": "RPNHead_bbox"}}
:::MLLOG {"namespace": "", "time_ms": 1639608893686, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/object_detection/maskrcnn_benchmark/modeling/roi_heads/box_head/roi_box_feature_extractors.py", "lineno": 83, "tensor": "ROI_BOX_FEATURE_EXTRACTOR_fc6"}}
:::MLLOG {"namespace": "", "time_ms": 1639608893697, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/object_detection/maskrcnn_benchmark/modeling/roi_heads/box_head/roi_box_feature_extractors.py", "lineno": 86, "tensor": "ROI_BOX_FEATURE_EXTRACTOR_fc7"}}
:::MLLOG {"namespace": "", "time_ms": 1639608893700, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/object_detection/maskrcnn_benchmark/modeling/roi_heads/box_head/roi_box_predictors.py", "lineno": 50, "tensor": "ROI_BOX_PREDICTOR_cls"}}
:::MLLOG {"namespace": "", "time_ms": 1639608893702, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/object_detection/maskrcnn_benchmark/modeling/roi_heads/box_head/roi_box_predictors.py", "lineno": 52, "tensor": "ROI_BOX_PREDICTOR_bbox"}}
:::MLLOG {"namespace": "", "time_ms": 1639608893713, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/object_detection/maskrcnn_benchmark/modeling/roi_heads/mask_head/roi_mask_feature_extractors.py", "lineno": 52, "tensor": "ROI_MASK_FEATURE_EXTRACTOR_fcn1"}}
:::MLLOG {"namespace": "", "time_ms": 1639608893722, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/object_detection/maskrcnn_benchmark/modeling/roi_heads/mask_head/roi_mask_feature_extractors.py", "lineno": 52, "tensor": "ROI_MASK_FEATURE_EXTRACTOR_fcn2"}}
:::MLLOG {"namespace": "", "time_ms": 1639608893731, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/object_detection/maskrcnn_benchmark/modeling/roi_heads/mask_head/roi_mask_feature_extractors.py", "lineno": 52, "tensor": "ROI_MASK_FEATURE_EXTRACTOR_fcn3"}}
:::MLLOG {"namespace": "", "time_ms": 1639608893740, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/object_detection/maskrcnn_benchmark/modeling/roi_heads/mask_head/roi_mask_feature_extractors.py", "lineno": 52, "tensor": "ROI_MASK_FEATURE_EXTRACTOR_fcn4"}}
/opt/conda/lib/python3.8/site-packages/torch/nn/modules/conv.py:1092: UserWarning: _ConvTransposeMixin is a deprecated internal class. Please consider using public APIs.
  warnings.warn(
:::MLLOG {"namespace": "", "time_ms": 1639608893744, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/object_detection/maskrcnn_benchmark/modeling/roi_heads/mask_head/roi_mask_predictors.py", "lineno": 42, "tensor": "ROI_MASK_PREDICTOR_fcn5"}}
:::MLLOG {"namespace": "", "time_ms": 1639608893744, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/object_detection/maskrcnn_benchmark/modeling/roi_heads/mask_head/roi_mask_predictors.py", "lineno": 43, "tensor": "ROI_MASK_PREDICTOR_fcn_logits"}}
[(800, 1344), (1344, 800)]
USE_CUDA_GRAPH :: per_gpu_batch_sizes = [(True, 24), (False, 24)]
/opt/conda/lib/python3.8/site-packages/torch/nn/modules/conv.py:1092: UserWarning: _ConvTransposeMixin is a deprecated internal class. Please consider using public APIs.
  warnings.warn(
[(800, 1344), (1344, 800)]
USE_CUDA_GRAPH :: per_gpu_batch_sizes = [(True, 24), (False, 24)]
/opt/conda/lib/python3.8/site-packages/torch/nn/modules/conv.py:1092: UserWarning: _ConvTransposeMixin is a deprecated internal class. Please consider using public APIs.
  warnings.warn(
[(800, 1344), (1344, 800)]
USE_CUDA_GRAPH :: per_gpu_batch_sizes = [(True, 24), (False, 24)]

run-mlperf--1-8m9qp:62:1110 [0] p2p_plugin.c:141 NCCL WARN NET/IB : Got async event : GID table change

run-mlperf--1-8m9qp:61:1106 [0] p2p_plugin.c:141 NCCL WARN NET/IB : Got async event : GID table change

run-mlperf--1-8m9qp:63:1111 [0] p2p_plugin.c:141 NCCL WARN NET/IB : Got async event : GID table change

run-mlperf--1-8m9qp:64:1112 [0] p2p_plugin.c:141 NCCL WARN NET/IB : Got async event : GID table change

run-mlperf--1-8m9qp:61:1106 [0] p2p_plugin.c:141 NCCL WARN NET/IB : Got async event : GID table change

run-mlperf--1-8m9qp:63:1111 [0] p2p_plugin.c:141 NCCL WARN NET/IB : Got async event : GID table change

run-mlperf--1-8m9qp:62:1110 [0] p2p_plugin.c:141 NCCL WARN NET/IB : Got async event : GID table change

run-mlperf--1-8m9qp:64:1112 [0] p2p_plugin.c:141 NCCL WARN NET/IB : Got async event : GID table change
Graphing

Graphing

Graphing

Graphing

Graphing

Graphing

Traceback (most recent call last):
  File "tools/train_mlperf.py", line 522, in <module>
    main()
  File "tools/train_mlperf.py", line 511, in main
    model, success = train(cfg, rank, world_size, args.distributed, random_number_generator, seed=master_seed)
  File "tools/train_mlperf.py", line 249, in train
    model.graphable, pool_id = graph(model.graphable,
  File "/workspace/object_detection/function.py", line 104, in graph
    outputs  = func_or_module(*sample_args)
  File "/opt/conda/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1056, in _call_impl
    return forward_call(*input, **kwargs)
  File "/workspace/object_detection/maskrcnn_benchmark/modeling/detector/generalized_rcnn.py", line 27, in forward
    features = self.backbone(images_tensor)
  File "/opt/conda/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1056, in _call_impl
    return forward_call(*input, **kwargs)
  File "/opt/conda/lib/python3.8/site-packages/torch/nn/modules/container.py", line 139, in forward
    input = module(input)
  File "/opt/conda/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1056, in _call_impl
    return forward_call(*input, **kwargs)
  File "/workspace/object_detection/maskrcnn_benchmark/modeling/backbone/fpn.py", line 72, in forward
    inner_top_down = interpolate_func(last_inner, scale_factor=2, mode="nearest")
  File "/workspace/object_detection/maskrcnn_benchmark/layers/nhwc/misc.py", line 112, in interpolate_nhwc
    return UpSampleNearest2d.upsample_nearest2d(input, _output_size(2))
  File "/workspace/object_detection/maskrcnn_benchmark/layers/nhwc/UpSampleNearest2d.py", line 50, in upsample_nearest2d
    return op(x)
  File "/opt/conda/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1056, in _call_impl
    return forward_call(*input, **kwargs)
  File "/workspace/object_detection/maskrcnn_benchmark/layers/nhwc/UpSampleNearest2d.py", line 45, in forward
    return UpSampleNearest2d_NHWC_Impl.apply(x,
  File "/workspace/object_detection/maskrcnn_benchmark/layers/nhwc/UpSampleNearest2d.py", line 26, in forward
    y = NHWC.upsample_nearest2d_cuda(x, output_size)
RuntimeError: captures_underway == 0INTERNAL ASSERT FAILED at "/opt/pytorch/pytorch/c10/cuda/CUDACachingAllocator.cpp":1209, please report a bug to PyTorch. 
[W CUDAGraph.cpp:226] Warning: CUDA warning: operation not permitted when stream is capturing (function reset)
[W CUDAGraph.cpp:226] Warning: CUDA warning: operation not permitted when stream is capturing (function reset)
[W CUDAGraph.cpp:226] Warning: CUDA warning: operation not permitted when stream is capturing (function reset)
[W CUDAGraph.cpp:226] Warning: CUDA warning: operation not permitted when stream is capturing (function reset)

run-mlperf--1-8m9qp:61:61 [0] init.cc:1041 NCCL WARN Cuda failure 'operation not permitted when stream is capturing'
terminate called after throwing an instance of 'c10::Error'
  what():  NCCL error in: /opt/pytorch/pytorch/torch/csrc/distributed/c10d/NCCLUtils.hpp:161, unhandled cuda error, NCCL version 21.1.4
ncclUnhandledCudaError: Call to CUDA function failed.
Exception raised from ncclCommAbort at /opt/pytorch/pytorch/torch/csrc/distributed/c10d/NCCLUtils.hpp:161 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x6c (0x7f9593f9663c in /opt/conda/lib/python3.8/site-packages/torch/lib/libc10.so)
frame #1: c10::detail::torchCheckFail(char const*, char const*, unsigned int, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&) + 0xfa (0x7f9593f61a28 in /opt/conda/lib/python3.8/site-packages/torch/lib/libc10.so)
frame #2: <unknown function> + 0x3c1e92e (0x7f9597c4492e in /opt/conda/lib/python3.8/site-packages/torch/lib/libtorch_cuda.so)
frame #3: c10d::ProcessGroupNCCL::~ProcessGroupNCCL() + 0xac (0x7f9597c253fc in /opt/conda/lib/python3.8/site-packages/torch/lib/libtorch_cuda.so)
frame #4: c10d::ProcessGroupNCCL::~ProcessGroupNCCL() + 0xd (0x7f9597c255cd in /opt/conda/lib/python3.8/site-packages/torch/lib/libtorch_cuda.so)
frame #5: <unknown function> + 0x10f3211 (0x7f95e9a90211 in /opt/conda/lib/python3.8/site-packages/torch/lib/libtorch_python.so)
frame #6: <unknown function> + 0x1105810 (0x7f95e9aa2810 in /opt/conda/lib/python3.8/site-packages/torch/lib/libtorch_python.so)
frame #7: <unknown function> + 0xa71082 (0x7f95e940e082 in /opt/conda/lib/python3.8/site-packages/torch/lib/libtorch_python.so)
frame #8: <unknown function> + 0xa72043 (0x7f95e940f043 in /opt/conda/lib/python3.8/site-packages/torch/lib/libtorch_python.so)
frame #9: <unknown function> + 0xf8b98 (0x559d205b7b98 in /opt/conda/bin/python)
frame #10: <unknown function> + 0xfa78b (0x559d205b978b in /opt/conda/bin/python)
frame #11: <unknown function> + 0xf8b4f (0x559d205b7b4f in /opt/conda/bin/python)
frame #12: <unknown function> + 0x1ef516 (0x559d206ae516 in /opt/conda/bin/python)
frame #13: <unknown function> + 0x11c574 (0x559d205db574 in /opt/conda/bin/python)
frame #14: _PyGC_CollectNoFail + 0x2b (0x559d207145db in /opt/conda/bin/python)
frame #15: PyImport_Cleanup + 0x371 (0x559d2072e7b1 in /opt/conda/bin/python)
frame #16: Py_FinalizeEx + 0x7a (0x559d2072ea9a in /opt/conda/bin/python)
frame #17: Py_RunMain + 0x1b8 (0x559d207335c8 in /opt/conda/bin/python)
frame #18: Py_BytesMain + 0x39 (0x559d20733939 in /opt/conda/bin/python)
frame #19: __libc_start_main + 0xf3 (0x7f962b9c10b3 in /usr/lib/x86_64-linux-gnu/libc.so.6)
frame #20: <unknown function> + 0x1e8f39 (0x559d206a7f39 in /opt/conda/bin/python)

Graphing

Graphing

Graphing

Graphing

Traceback (most recent call last):
  File "tools/train_mlperf.py", line 522, in <module>
    main()
  File "tools/train_mlperf.py", line 511, in main
    model, success = train(cfg, rank, world_size, args.distributed, random_number_generator, seed=master_seed)
  File "tools/train_mlperf.py", line 249, in train
    model.graphable, pool_id = graph(model.graphable,
  File "/workspace/object_detection/function.py", line 104, in graph
    outputs  = func_or_module(*sample_args)
  File "/opt/conda/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1056, in _call_impl
    return forward_call(*input, **kwargs)
  File "/workspace/object_detection/maskrcnn_benchmark/modeling/detector/generalized_rcnn.py", line 27, in forward
    features = self.backbone(images_tensor)
  File "/opt/conda/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1056, in _call_impl
    return forward_call(*input, **kwargs)
  File "/opt/conda/lib/python3.8/site-packages/torch/nn/modules/container.py", line 139, in forward
    input = module(input)
  File "/opt/conda/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1056, in _call_impl
    return forward_call(*input, **kwargs)
  File "/workspace/object_detection/maskrcnn_benchmark/modeling/backbone/fpn.py", line 72, in forward
    inner_top_down = interpolate_func(last_inner, scale_factor=2, mode="nearest")
  File "/workspace/object_detection/maskrcnn_benchmark/layers/nhwc/misc.py", line 112, in interpolate_nhwc
    return UpSampleNearest2d.upsample_nearest2d(input, _output_size(2))
  File "/workspace/object_detection/maskrcnn_benchmark/layers/nhwc/UpSampleNearest2d.py", line 50, in upsample_nearest2d
    return op(x)
  File "/opt/conda/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1056, in _call_impl
    return forward_call(*input, **kwargs)
  File "/workspace/object_detection/maskrcnn_benchmark/layers/nhwc/UpSampleNearest2d.py", line 45, in forward
    return UpSampleNearest2d_NHWC_Impl.apply(x,
  File "/workspace/object_detection/maskrcnn_benchmark/layers/nhwc/UpSampleNearest2d.py", line 26, in forward
    y = NHWC.upsample_nearest2d_cuda(x, output_size)
RuntimeError: captures_underway == 0INTERNAL ASSERT FAILED at "/opt/pytorch/pytorch/c10/cuda/CUDACachingAllocator.cpp":1209, please report a bug to PyTorch. 
[W CUDAGraph.cpp:226] Warning: CUDA warning: operation not permitted when stream is capturing (function reset)
[W CUDAGraph.cpp:226] Warning: CUDA warning: operation not permitted when stream is capturing (function reset)
[W CUDAGraph.cpp:226] Warning: CUDA warning: operation not permitted when stream is capturing (function reset)
[W CUDAGraph.cpp:226] Warning: CUDA warning: operation not permitted when stream is capturing (function reset)

run-mlperf--1-8m9qp:64:64 [3] init.cc:1041 NCCL WARN Cuda failure 'operation not permitted when stream is capturing'
terminate called after throwing an instance of 'c10::Error'
  what():  NCCL error in: /opt/pytorch/pytorch/torch/csrc/distributed/c10d/NCCLUtils.hpp:161, unhandled cuda error, NCCL version 21.1.4
ncclUnhandledCudaError: Call to CUDA function failed.
Exception raised from ncclCommAbort at /opt/pytorch/pytorch/torch/csrc/distributed/c10d/NCCLUtils.hpp:161 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x6c (0x7f37a316f63c in /opt/conda/lib/python3.8/site-packages/torch/lib/libc10.so)
frame #1: c10::detail::torchCheckFail(char const*, char const*, unsigned int, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&) + 0xfa (0x7f37a313aa28 in /opt/conda/lib/python3.8/site-packages/torch/lib/libc10.so)
frame #2: <unknown function> + 0x3c1e92e (0x7f37a6e1d92e in /opt/conda/lib/python3.8/site-packages/torch/lib/libtorch_cuda.so)
frame #3: c10d::ProcessGroupNCCL::~ProcessGroupNCCL() + 0xac (0x7f37a6dfe3fc in /opt/conda/lib/python3.8/site-packages/torch/lib/libtorch_cuda.so)
frame #4: c10d::ProcessGroupNCCL::~ProcessGroupNCCL() + 0xd (0x7f37a6dfe5cd in /opt/conda/lib/python3.8/site-packages/torch/lib/libtorch_cuda.so)
frame #5: <unknown function> + 0x10f3211 (0x7f37f8c6e211 in /opt/conda/lib/python3.8/site-packages/torch/lib/libtorch_python.so)
frame #6: <unknown function> + 0x1105810 (0x7f37f8c80810 in /opt/conda/lib/python3.8/site-packages/torch/lib/libtorch_python.so)
frame #7: <unknown function> + 0xa71082 (0x7f37f85ec082 in /opt/conda/lib/python3.8/site-packages/torch/lib/libtorch_python.so)
frame #8: <unknown function> + 0xa72043 (0x7f37f85ed043 in /opt/conda/lib/python3.8/site-packages/torch/lib/libtorch_python.so)
frame #9: <unknown function> + 0xf8b98 (0x565530e4cb98 in /opt/conda/bin/python)
frame #10: <unknown function> + 0xfa78b (0x565530e4e78b in /opt/conda/bin/python)
frame #11: <unknown function> + 0xf8b4f (0x565530e4cb4f in /opt/conda/bin/python)
frame #12: <unknown function> + 0x1ef516 (0x565530f43516 in /opt/conda/bin/python)
frame #13: <unknown function> + 0x11c574 (0x565530e70574 in /opt/conda/bin/python)
frame #14: _PyGC_CollectNoFail + 0x2b (0x565530fa95db in /opt/conda/bin/python)
frame #15: PyImport_Cleanup + 0x371 (0x565530fc37b1 in /opt/conda/bin/python)
frame #16: Py_FinalizeEx + 0x7a (0x565530fc3a9a in /opt/conda/bin/python)
frame #17: Py_RunMain + 0x1b8 (0x565530fc85c8 in /opt/conda/bin/python)
frame #18: Py_BytesMain + 0x39 (0x565530fc8939 in /opt/conda/bin/python)
frame #19: __libc_start_main + 0xf3 (0x7f383ab950b3 in /usr/lib/x86_64-linux-gnu/libc.so.6)
frame #20: <unknown function> + 0x1e8f39 (0x565530f3cf39 in /opt/conda/bin/python)

Graphing

Traceback (most recent call last):
  File "tools/train_mlperf.py", line 522, in <module>
    main()
  File "tools/train_mlperf.py", line 511, in main
    model, success = train(cfg, rank, world_size, args.distributed, random_number_generator, seed=master_seed)
  File "tools/train_mlperf.py", line 249, in train
    model.graphable, pool_id = graph(model.graphable,
  File "/workspace/object_detection/function.py", line 104, in graph
    outputs  = func_or_module(*sample_args)
  File "/opt/conda/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1056, in _call_impl
    return forward_call(*input, **kwargs)
  File "/workspace/object_detection/maskrcnn_benchmark/modeling/detector/generalized_rcnn.py", line 27, in forward
    features = self.backbone(images_tensor)
  File "/opt/conda/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1056, in _call_impl
    return forward_call(*input, **kwargs)
  File "/opt/conda/lib/python3.8/site-packages/torch/nn/modules/container.py", line 139, in forward
    input = module(input)
  File "/opt/conda/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1056, in _call_impl
    return forward_call(*input, **kwargs)
  File "/workspace/object_detection/maskrcnn_benchmark/modeling/backbone/fpn.py", line 72, in forward
    inner_top_down = interpolate_func(last_inner, scale_factor=2, mode="nearest")
  File "/workspace/object_detection/maskrcnn_benchmark/layers/nhwc/misc.py", line 112, in interpolate_nhwc
    return UpSampleNearest2d.upsample_nearest2d(input, _output_size(2))
  File "/workspace/object_detection/maskrcnn_benchmark/layers/nhwc/UpSampleNearest2d.py", line 50, in upsample_nearest2d
    return op(x)
  File "/opt/conda/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1056, in _call_impl
    return forward_call(*input, **kwargs)
  File "/workspace/object_detection/maskrcnn_benchmark/layers/nhwc/UpSampleNearest2d.py", line 45, in forward
    return UpSampleNearest2d_NHWC_Impl.apply(x,
  File "/workspace/object_detection/maskrcnn_benchmark/layers/nhwc/UpSampleNearest2d.py", line 26, in forward
    y = NHWC.upsample_nearest2d_cuda(x, output_size)
RuntimeError: captures_underway == 0INTERNAL ASSERT FAILED at "/opt/pytorch/pytorch/c10/cuda/CUDACachingAllocator.cpp":1209, please report a bug to PyTorch. 
[W CUDAGraph.cpp:226] Warning: CUDA warning: operation not permitted when stream is capturing (function reset)
[W CUDAGraph.cpp:226] Warning: CUDA warning: operation not permitted when stream is capturing (function reset)
[W CUDAGraph.cpp:226] Warning: CUDA warning: operation not permitted when stream is capturing (function reset)
[W CUDAGraph.cpp:226] Warning: CUDA warning: operation not permitted when stream is capturing (function reset)

run-mlperf--1-8m9qp:62:62 [1] init.cc:1041 NCCL WARN Cuda failure 'operation not permitted when stream is capturing'
terminate called after throwing an instance of 'c10::Error'
  what():  NCCL error in: /opt/pytorch/pytorch/torch/csrc/distributed/c10d/NCCLUtils.hpp:161, unhandled cuda error, NCCL version 21.1.4
ncclUnhandledCudaError: Call to CUDA function failed.
Exception raised from ncclCommAbort at /opt/pytorch/pytorch/torch/csrc/distributed/c10d/NCCLUtils.hpp:161 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x6c (0x7f3c92dab63c in /opt/conda/lib/python3.8/site-packages/torch/lib/libc10.so)
frame #1: c10::detail::torchCheckFail(char const*, char const*, unsigned int, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&) + 0xfa (0x7f3c92d76a28 in /opt/conda/lib/python3.8/site-packages/torch/lib/libc10.so)
frame #2: <unknown function> + 0x3c1e92e (0x7f3c96a5992e in /opt/conda/lib/python3.8/site-packages/torch/lib/libtorch_cuda.so)
frame #3: c10d::ProcessGroupNCCL::~ProcessGroupNCCL() + 0xac (0x7f3c96a3a3fc in /opt/conda/lib/python3.8/site-packages/torch/lib/libtorch_cuda.so)
frame #4: c10d::ProcessGroupNCCL::~ProcessGroupNCCL() + 0xd (0x7f3c96a3a5cd in /opt/conda/lib/python3.8/site-packages/torch/lib/libtorch_cuda.so)
frame #5: <unknown function> + 0x10f3211 (0x7f3ce88aa211 in /opt/conda/lib/python3.8/site-packages/torch/lib/libtorch_python.so)
frame #6: <unknown function> + 0x1105810 (0x7f3ce88bc810 in /opt/conda/lib/python3.8/site-packages/torch/lib/libtorch_python.so)
frame #7: <unknown function> + 0xa71082 (0x7f3ce8228082 in /opt/conda/lib/python3.8/site-packages/torch/lib/libtorch_python.so)
frame #8: <unknown function> + 0xa72043 (0x7f3ce8229043 in /opt/conda/lib/python3.8/site-packages/torch/lib/libtorch_python.so)
frame #9: <unknown function> + 0xf8b98 (0x5605925e0b98 in /opt/conda/bin/python)
frame #10: <unknown function> + 0xfa78b (0x5605925e278b in /opt/conda/bin/python)
frame #11: <unknown function> + 0xf8b4f (0x5605925e0b4f in /opt/conda/bin/python)
frame #12: <unknown function> + 0x1ef516 (0x5605926d7516 in /opt/conda/bin/python)
frame #13: <unknown function> + 0x11c574 (0x560592604574 in /opt/conda/bin/python)
frame #14: _PyGC_CollectNoFail + 0x2b (0x56059273d5db in /opt/conda/bin/python)
frame #15: PyImport_Cleanup + 0x371 (0x5605927577b1 in /opt/conda/bin/python)
frame #16: Py_FinalizeEx + 0x7a (0x560592757a9a in /opt/conda/bin/python)
frame #17: Py_RunMain + 0x1b8 (0x56059275c5c8 in /opt/conda/bin/python)
frame #18: Py_BytesMain + 0x39 (0x56059275c939 in /opt/conda/bin/python)
frame #19: __libc_start_main + 0xf3 (0x7f3d2a7d10b3 in /usr/lib/x86_64-linux-gnu/libc.so.6)
frame #20: <unknown function> + 0x1e8f39 (0x5605926d0f39 in /opt/conda/bin/python)

Graphing

Traceback (most recent call last):
  File "tools/train_mlperf.py", line 522, in <module>
    main()
  File "tools/train_mlperf.py", line 511, in main
    model, success = train(cfg, rank, world_size, args.distributed, random_number_generator, seed=master_seed)
  File "tools/train_mlperf.py", line 249, in train
    model.graphable, pool_id = graph(model.graphable,
  File "/workspace/object_detection/function.py", line 104, in graph
    outputs  = func_or_module(*sample_args)
  File "/opt/conda/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1056, in _call_impl
    return forward_call(*input, **kwargs)
  File "/workspace/object_detection/maskrcnn_benchmark/modeling/detector/generalized_rcnn.py", line 27, in forward
    features = self.backbone(images_tensor)
  File "/opt/conda/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1056, in _call_impl
    return forward_call(*input, **kwargs)
  File "/opt/conda/lib/python3.8/site-packages/torch/nn/modules/container.py", line 139, in forward
    input = module(input)
  File "/opt/conda/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1056, in _call_impl
    return forward_call(*input, **kwargs)
  File "/workspace/object_detection/maskrcnn_benchmark/modeling/backbone/fpn.py", line 72, in forward
    inner_top_down = interpolate_func(last_inner, scale_factor=2, mode="nearest")
  File "/workspace/object_detection/maskrcnn_benchmark/layers/nhwc/misc.py", line 112, in interpolate_nhwc
    return UpSampleNearest2d.upsample_nearest2d(input, _output_size(2))
  File "/workspace/object_detection/maskrcnn_benchmark/layers/nhwc/UpSampleNearest2d.py", line 50, in upsample_nearest2d
    return op(x)
  File "/opt/conda/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1056, in _call_impl
    return forward_call(*input, **kwargs)
  File "/workspace/object_detection/maskrcnn_benchmark/layers/nhwc/UpSampleNearest2d.py", line 45, in forward
    return UpSampleNearest2d_NHWC_Impl.apply(x,
  File "/workspace/object_detection/maskrcnn_benchmark/layers/nhwc/UpSampleNearest2d.py", line 26, in forward
    y = NHWC.upsample_nearest2d_cuda(x, output_size)
RuntimeError: captures_underway == 0INTERNAL ASSERT FAILED at "/opt/pytorch/pytorch/c10/cuda/CUDACachingAllocator.cpp":1209, please report a bug to PyTorch. 
[W CUDAGraph.cpp:226] Warning: CUDA warning: operation not permitted when stream is capturing (function reset)
[W CUDAGraph.cpp:226] Warning: CUDA warning: operation not permitted when stream is capturing (function reset)
[W CUDAGraph.cpp:226] Warning: CUDA warning: operation not permitted when stream is capturing (function reset)
[W CUDAGraph.cpp:226] Warning: CUDA warning: operation not permitted when stream is capturing (function reset)

run-mlperf--1-8m9qp:63:63 [2] init.cc:1041 NCCL WARN Cuda failure 'operation not permitted when stream is capturing'
terminate called after throwing an instance of 'c10::Error'
  what():  NCCL error in: /opt/pytorch/pytorch/torch/csrc/distributed/c10d/NCCLUtils.hpp:161, unhandled cuda error, NCCL version 21.1.4
ncclUnhandledCudaError: Call to CUDA function failed.
Exception raised from ncclCommAbort at /opt/pytorch/pytorch/torch/csrc/distributed/c10d/NCCLUtils.hpp:161 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x6c (0x7fbf23d5963c in /opt/conda/lib/python3.8/site-packages/torch/lib/libc10.so)
frame #1: c10::detail::torchCheckFail(char const*, char const*, unsigned int, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&) + 0xfa (0x7fbf23d24a28 in /opt/conda/lib/python3.8/site-packages/torch/lib/libc10.so)
frame #2: <unknown function> + 0x3c1e92e (0x7fbf27a0792e in /opt/conda/lib/python3.8/site-packages/torch/lib/libtorch_cuda.so)
frame #3: c10d::ProcessGroupNCCL::~ProcessGroupNCCL() + 0xac (0x7fbf279e83fc in /opt/conda/lib/python3.8/site-packages/torch/lib/libtorch_cuda.so)
frame #4: c10d::ProcessGroupNCCL::~ProcessGroupNCCL() + 0xd (0x7fbf279e85cd in /opt/conda/lib/python3.8/site-packages/torch/lib/libtorch_cuda.so)
frame #5: <unknown function> + 0x10f3211 (0x7fbf79858211 in /opt/conda/lib/python3.8/site-packages/torch/lib/libtorch_python.so)
frame #6: <unknown function> + 0x1105810 (0x7fbf7986a810 in /opt/conda/lib/python3.8/site-packages/torch/lib/libtorch_python.so)
frame #7: <unknown function> + 0xa71082 (0x7fbf791d6082 in /opt/conda/lib/python3.8/site-packages/torch/lib/libtorch_python.so)
frame #8: <unknown function> + 0xa72043 (0x7fbf791d7043 in /opt/conda/lib/python3.8/site-packages/torch/lib/libtorch_python.so)
frame #9: <unknown function> + 0xf8b98 (0x55a0270d5b98 in /opt/conda/bin/python)
frame #10: <unknown function> + 0xfa78b (0x55a0270d778b in /opt/conda/bin/python)
frame #11: <unknown function> + 0xf8b4f (0x55a0270d5b4f in /opt/conda/bin/python)
frame #12: <unknown function> + 0x1ef516 (0x55a0271cc516 in /opt/conda/bin/python)
frame #13: <unknown function> + 0x11c574 (0x55a0270f9574 in /opt/conda/bin/python)
frame #14: _PyGC_CollectNoFail + 0x2b (0x55a0272325db in /opt/conda/bin/python)
frame #15: PyImport_Cleanup + 0x371 (0x55a02724c7b1 in /opt/conda/bin/python)
frame #16: Py_FinalizeEx + 0x7a (0x55a02724ca9a in /opt/conda/bin/python)
frame #17: Py_RunMain + 0x1b8 (0x55a0272515c8 in /opt/conda/bin/python)
frame #18: Py_BytesMain + 0x39 (0x55a027251939 in /opt/conda/bin/python)
frame #19: __libc_start_main + 0xf3 (0x7fbfbb77f0b3 in /usr/lib/x86_64-linux-gnu/libc.so.6)
frame #20: <unknown function> + 0x1e8f39 (0x55a0271c5f39 in /opt/conda/bin/python)

++ date
Wed Dec 15 22:57:46 UTC 2021
++ echo failed
failed
++ exit 1
